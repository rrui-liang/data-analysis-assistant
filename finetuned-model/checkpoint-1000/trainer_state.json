{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.001,
      "grad_norm": 34.546817779541016,
      "learning_rate": 4.995e-05,
      "loss": 1.0412,
      "step": 1
    },
    {
      "epoch": 0.002,
      "grad_norm": 22.457082748413086,
      "learning_rate": 4.99e-05,
      "loss": 0.6476,
      "step": 2
    },
    {
      "epoch": 0.003,
      "grad_norm": 14.760665893554688,
      "learning_rate": 4.9850000000000006e-05,
      "loss": 0.3822,
      "step": 3
    },
    {
      "epoch": 0.004,
      "grad_norm": 43.003841400146484,
      "learning_rate": 4.9800000000000004e-05,
      "loss": 1.0022,
      "step": 4
    },
    {
      "epoch": 0.005,
      "grad_norm": 23.279705047607422,
      "learning_rate": 4.975e-05,
      "loss": 0.8834,
      "step": 5
    },
    {
      "epoch": 0.006,
      "grad_norm": 14.609851837158203,
      "learning_rate": 4.97e-05,
      "loss": 0.3289,
      "step": 6
    },
    {
      "epoch": 0.007,
      "grad_norm": 44.80176544189453,
      "learning_rate": 4.965e-05,
      "loss": 1.1584,
      "step": 7
    },
    {
      "epoch": 0.008,
      "grad_norm": 12.220141410827637,
      "learning_rate": 4.96e-05,
      "loss": 0.2851,
      "step": 8
    },
    {
      "epoch": 0.009,
      "grad_norm": 26.3837890625,
      "learning_rate": 4.9550000000000005e-05,
      "loss": 1.4056,
      "step": 9
    },
    {
      "epoch": 0.01,
      "grad_norm": 39.604244232177734,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 1.4496,
      "step": 10
    },
    {
      "epoch": 0.011,
      "grad_norm": 30.490489959716797,
      "learning_rate": 4.945e-05,
      "loss": 1.8049,
      "step": 11
    },
    {
      "epoch": 0.012,
      "grad_norm": 15.156088829040527,
      "learning_rate": 4.94e-05,
      "loss": 0.4571,
      "step": 12
    },
    {
      "epoch": 0.013,
      "grad_norm": 23.58324432373047,
      "learning_rate": 4.935e-05,
      "loss": 1.1197,
      "step": 13
    },
    {
      "epoch": 0.014,
      "grad_norm": 7.598104953765869,
      "learning_rate": 4.93e-05,
      "loss": 0.0742,
      "step": 14
    },
    {
      "epoch": 0.015,
      "grad_norm": 2.8550212383270264,
      "learning_rate": 4.9250000000000004e-05,
      "loss": 0.0732,
      "step": 15
    },
    {
      "epoch": 0.016,
      "grad_norm": 5.689892768859863,
      "learning_rate": 4.92e-05,
      "loss": 0.1516,
      "step": 16
    },
    {
      "epoch": 0.017,
      "grad_norm": 19.305908203125,
      "learning_rate": 4.915e-05,
      "loss": 0.3742,
      "step": 17
    },
    {
      "epoch": 0.018,
      "grad_norm": 43.830684661865234,
      "learning_rate": 4.91e-05,
      "loss": 2.6465,
      "step": 18
    },
    {
      "epoch": 0.019,
      "grad_norm": 2.086003303527832,
      "learning_rate": 4.905e-05,
      "loss": 0.0446,
      "step": 19
    },
    {
      "epoch": 0.02,
      "grad_norm": 15.615732192993164,
      "learning_rate": 4.9e-05,
      "loss": 0.3955,
      "step": 20
    },
    {
      "epoch": 0.021,
      "grad_norm": 7.7823944091796875,
      "learning_rate": 4.8950000000000004e-05,
      "loss": 0.0987,
      "step": 21
    },
    {
      "epoch": 0.022,
      "grad_norm": 5.368682384490967,
      "learning_rate": 4.89e-05,
      "loss": 0.0999,
      "step": 22
    },
    {
      "epoch": 0.023,
      "grad_norm": 16.52031135559082,
      "learning_rate": 4.885e-05,
      "loss": 0.4719,
      "step": 23
    },
    {
      "epoch": 0.024,
      "grad_norm": 10.990058898925781,
      "learning_rate": 4.88e-05,
      "loss": 0.1866,
      "step": 24
    },
    {
      "epoch": 0.025,
      "grad_norm": 18.379167556762695,
      "learning_rate": 4.875e-05,
      "loss": 0.4714,
      "step": 25
    },
    {
      "epoch": 0.026,
      "grad_norm": 2.636007308959961,
      "learning_rate": 4.87e-05,
      "loss": 0.07,
      "step": 26
    },
    {
      "epoch": 0.027,
      "grad_norm": 16.314943313598633,
      "learning_rate": 4.8650000000000003e-05,
      "loss": 0.5881,
      "step": 27
    },
    {
      "epoch": 0.028,
      "grad_norm": 16.70706558227539,
      "learning_rate": 4.86e-05,
      "loss": 0.5849,
      "step": 28
    },
    {
      "epoch": 0.029,
      "grad_norm": 0.6520327925682068,
      "learning_rate": 4.855e-05,
      "loss": 0.0128,
      "step": 29
    },
    {
      "epoch": 0.03,
      "grad_norm": 15.087438583374023,
      "learning_rate": 4.85e-05,
      "loss": 0.4464,
      "step": 30
    },
    {
      "epoch": 0.031,
      "grad_norm": 0.9709572792053223,
      "learning_rate": 4.845e-05,
      "loss": 0.019,
      "step": 31
    },
    {
      "epoch": 0.032,
      "grad_norm": 1.6319758892059326,
      "learning_rate": 4.8400000000000004e-05,
      "loss": 0.0366,
      "step": 32
    },
    {
      "epoch": 0.033,
      "grad_norm": 0.8258061408996582,
      "learning_rate": 4.835e-05,
      "loss": 0.0227,
      "step": 33
    },
    {
      "epoch": 0.034,
      "grad_norm": 0.4499688744544983,
      "learning_rate": 4.83e-05,
      "loss": 0.0127,
      "step": 34
    },
    {
      "epoch": 0.035,
      "grad_norm": 4.559933185577393,
      "learning_rate": 4.825e-05,
      "loss": 0.1437,
      "step": 35
    },
    {
      "epoch": 0.036,
      "grad_norm": 2.4578897953033447,
      "learning_rate": 4.82e-05,
      "loss": 0.0576,
      "step": 36
    },
    {
      "epoch": 0.037,
      "grad_norm": 0.8297305107116699,
      "learning_rate": 4.815e-05,
      "loss": 0.0266,
      "step": 37
    },
    {
      "epoch": 0.038,
      "grad_norm": 7.834898471832275,
      "learning_rate": 4.8100000000000004e-05,
      "loss": 0.1143,
      "step": 38
    },
    {
      "epoch": 0.039,
      "grad_norm": 0.5032276511192322,
      "learning_rate": 4.805e-05,
      "loss": 0.0083,
      "step": 39
    },
    {
      "epoch": 0.04,
      "grad_norm": 5.889496803283691,
      "learning_rate": 4.8e-05,
      "loss": 0.0862,
      "step": 40
    },
    {
      "epoch": 0.041,
      "grad_norm": 1.7985724210739136,
      "learning_rate": 4.795e-05,
      "loss": 0.0172,
      "step": 41
    },
    {
      "epoch": 0.042,
      "grad_norm": 1.0044012069702148,
      "learning_rate": 4.79e-05,
      "loss": 0.0219,
      "step": 42
    },
    {
      "epoch": 0.043,
      "grad_norm": 0.749669075012207,
      "learning_rate": 4.785e-05,
      "loss": 0.0176,
      "step": 43
    },
    {
      "epoch": 0.044,
      "grad_norm": 5.711085796356201,
      "learning_rate": 4.78e-05,
      "loss": 0.0813,
      "step": 44
    },
    {
      "epoch": 0.045,
      "grad_norm": 11.771438598632812,
      "learning_rate": 4.775e-05,
      "loss": 0.2755,
      "step": 45
    },
    {
      "epoch": 0.046,
      "grad_norm": 5.275345325469971,
      "learning_rate": 4.77e-05,
      "loss": 0.1147,
      "step": 46
    },
    {
      "epoch": 0.047,
      "grad_norm": 0.1320856809616089,
      "learning_rate": 4.765e-05,
      "loss": 0.0034,
      "step": 47
    },
    {
      "epoch": 0.048,
      "grad_norm": 2.275420665740967,
      "learning_rate": 4.76e-05,
      "loss": 0.03,
      "step": 48
    },
    {
      "epoch": 0.049,
      "grad_norm": 5.887282848358154,
      "learning_rate": 4.755e-05,
      "loss": 0.0617,
      "step": 49
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.5869258642196655,
      "learning_rate": 4.75e-05,
      "loss": 0.0173,
      "step": 50
    },
    {
      "epoch": 0.051,
      "grad_norm": 2.2841694355010986,
      "learning_rate": 4.745e-05,
      "loss": 0.0485,
      "step": 51
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.7007589340209961,
      "learning_rate": 4.74e-05,
      "loss": 0.0153,
      "step": 52
    },
    {
      "epoch": 0.053,
      "grad_norm": 0.45061206817626953,
      "learning_rate": 4.735e-05,
      "loss": 0.0093,
      "step": 53
    },
    {
      "epoch": 0.054,
      "grad_norm": 6.78779935836792,
      "learning_rate": 4.73e-05,
      "loss": 0.1217,
      "step": 54
    },
    {
      "epoch": 0.055,
      "grad_norm": 1.5859071016311646,
      "learning_rate": 4.7249999999999997e-05,
      "loss": 0.0294,
      "step": 55
    },
    {
      "epoch": 0.056,
      "grad_norm": 164.86903381347656,
      "learning_rate": 4.72e-05,
      "loss": 0.3365,
      "step": 56
    },
    {
      "epoch": 0.057,
      "grad_norm": 0.47634243965148926,
      "learning_rate": 4.715e-05,
      "loss": 0.0071,
      "step": 57
    },
    {
      "epoch": 0.058,
      "grad_norm": 0.30338969826698303,
      "learning_rate": 4.71e-05,
      "loss": 0.0073,
      "step": 58
    },
    {
      "epoch": 0.059,
      "grad_norm": 4.1884260177612305,
      "learning_rate": 4.705e-05,
      "loss": 0.0458,
      "step": 59
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.980607271194458,
      "learning_rate": 4.7e-05,
      "loss": 0.0273,
      "step": 60
    },
    {
      "epoch": 0.061,
      "grad_norm": 2.087158441543579,
      "learning_rate": 4.695e-05,
      "loss": 0.029,
      "step": 61
    },
    {
      "epoch": 0.062,
      "grad_norm": 0.3471624255180359,
      "learning_rate": 4.69e-05,
      "loss": 0.0057,
      "step": 62
    },
    {
      "epoch": 0.063,
      "grad_norm": 0.8031347990036011,
      "learning_rate": 4.685000000000001e-05,
      "loss": 0.0099,
      "step": 63
    },
    {
      "epoch": 0.064,
      "grad_norm": 2.6194350719451904,
      "learning_rate": 4.6800000000000006e-05,
      "loss": 0.0408,
      "step": 64
    },
    {
      "epoch": 0.065,
      "grad_norm": 35.37989044189453,
      "learning_rate": 4.6750000000000005e-05,
      "loss": 2.7367,
      "step": 65
    },
    {
      "epoch": 0.066,
      "grad_norm": 2.2076966762542725,
      "learning_rate": 4.6700000000000003e-05,
      "loss": 0.032,
      "step": 66
    },
    {
      "epoch": 0.067,
      "grad_norm": 0.6799805760383606,
      "learning_rate": 4.665e-05,
      "loss": 0.0114,
      "step": 67
    },
    {
      "epoch": 0.068,
      "grad_norm": 0.07195655256509781,
      "learning_rate": 4.660000000000001e-05,
      "loss": 0.002,
      "step": 68
    },
    {
      "epoch": 0.069,
      "grad_norm": 0.21803317964076996,
      "learning_rate": 4.655000000000001e-05,
      "loss": 0.0059,
      "step": 69
    },
    {
      "epoch": 0.07,
      "grad_norm": 5.6210832595825195,
      "learning_rate": 4.6500000000000005e-05,
      "loss": 0.0702,
      "step": 70
    },
    {
      "epoch": 0.071,
      "grad_norm": 3.614997386932373,
      "learning_rate": 4.6450000000000004e-05,
      "loss": 0.0775,
      "step": 71
    },
    {
      "epoch": 0.072,
      "grad_norm": 1.34774649143219,
      "learning_rate": 4.64e-05,
      "loss": 0.0329,
      "step": 72
    },
    {
      "epoch": 0.073,
      "grad_norm": 0.5324451327323914,
      "learning_rate": 4.635e-05,
      "loss": 0.0089,
      "step": 73
    },
    {
      "epoch": 0.074,
      "grad_norm": 0.04201672226190567,
      "learning_rate": 4.630000000000001e-05,
      "loss": 0.0009,
      "step": 74
    },
    {
      "epoch": 0.075,
      "grad_norm": 8.585143089294434,
      "learning_rate": 4.6250000000000006e-05,
      "loss": 0.1113,
      "step": 75
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.34384313225746155,
      "learning_rate": 4.6200000000000005e-05,
      "loss": 0.0064,
      "step": 76
    },
    {
      "epoch": 0.077,
      "grad_norm": 0.39259955286979675,
      "learning_rate": 4.6150000000000004e-05,
      "loss": 0.007,
      "step": 77
    },
    {
      "epoch": 0.078,
      "grad_norm": 0.4492223262786865,
      "learning_rate": 4.61e-05,
      "loss": 0.0084,
      "step": 78
    },
    {
      "epoch": 0.079,
      "grad_norm": 2.185757875442505,
      "learning_rate": 4.605e-05,
      "loss": 0.019,
      "step": 79
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.2909368574619293,
      "learning_rate": 4.600000000000001e-05,
      "loss": 0.005,
      "step": 80
    },
    {
      "epoch": 0.081,
      "grad_norm": 0.19660726189613342,
      "learning_rate": 4.5950000000000006e-05,
      "loss": 0.002,
      "step": 81
    },
    {
      "epoch": 0.082,
      "grad_norm": 1.1795576810836792,
      "learning_rate": 4.5900000000000004e-05,
      "loss": 0.0107,
      "step": 82
    },
    {
      "epoch": 0.083,
      "grad_norm": 1.3788468837738037,
      "learning_rate": 4.585e-05,
      "loss": 0.0259,
      "step": 83
    },
    {
      "epoch": 0.084,
      "grad_norm": 1.4696155786514282,
      "learning_rate": 4.58e-05,
      "loss": 0.0179,
      "step": 84
    },
    {
      "epoch": 0.085,
      "grad_norm": 6.911484241485596,
      "learning_rate": 4.575e-05,
      "loss": 0.0958,
      "step": 85
    },
    {
      "epoch": 0.086,
      "grad_norm": 4.4230780601501465,
      "learning_rate": 4.5700000000000006e-05,
      "loss": 0.0181,
      "step": 86
    },
    {
      "epoch": 0.087,
      "grad_norm": 0.42903459072113037,
      "learning_rate": 4.5650000000000005e-05,
      "loss": 0.01,
      "step": 87
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.07359194755554199,
      "learning_rate": 4.5600000000000004e-05,
      "loss": 0.0012,
      "step": 88
    },
    {
      "epoch": 0.089,
      "grad_norm": 0.2858981490135193,
      "learning_rate": 4.555e-05,
      "loss": 0.0028,
      "step": 89
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.48910772800445557,
      "learning_rate": 4.55e-05,
      "loss": 0.0055,
      "step": 90
    },
    {
      "epoch": 0.091,
      "grad_norm": 2.0608763694763184,
      "learning_rate": 4.545000000000001e-05,
      "loss": 0.0227,
      "step": 91
    },
    {
      "epoch": 0.092,
      "grad_norm": 0.15513360500335693,
      "learning_rate": 4.5400000000000006e-05,
      "loss": 0.0024,
      "step": 92
    },
    {
      "epoch": 0.093,
      "grad_norm": 2.7895936965942383,
      "learning_rate": 4.5350000000000005e-05,
      "loss": 0.027,
      "step": 93
    },
    {
      "epoch": 0.094,
      "grad_norm": 0.179861381649971,
      "learning_rate": 4.53e-05,
      "loss": 0.0027,
      "step": 94
    },
    {
      "epoch": 0.095,
      "grad_norm": 0.17366936802864075,
      "learning_rate": 4.525e-05,
      "loss": 0.0028,
      "step": 95
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.009713927283883095,
      "learning_rate": 4.52e-05,
      "loss": 0.0002,
      "step": 96
    },
    {
      "epoch": 0.097,
      "grad_norm": 0.10982531309127808,
      "learning_rate": 4.5150000000000006e-05,
      "loss": 0.0023,
      "step": 97
    },
    {
      "epoch": 0.098,
      "grad_norm": 0.4304644763469696,
      "learning_rate": 4.5100000000000005e-05,
      "loss": 0.0061,
      "step": 98
    },
    {
      "epoch": 0.099,
      "grad_norm": 0.4270769953727722,
      "learning_rate": 4.5050000000000004e-05,
      "loss": 0.0067,
      "step": 99
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.05006752535700798,
      "learning_rate": 4.5e-05,
      "loss": 0.0007,
      "step": 100
    },
    {
      "epoch": 0.101,
      "grad_norm": 0.29373791813850403,
      "learning_rate": 4.495e-05,
      "loss": 0.0054,
      "step": 101
    },
    {
      "epoch": 0.102,
      "grad_norm": 0.4465034604072571,
      "learning_rate": 4.49e-05,
      "loss": 0.0098,
      "step": 102
    },
    {
      "epoch": 0.103,
      "grad_norm": 0.1006869301199913,
      "learning_rate": 4.4850000000000006e-05,
      "loss": 0.0023,
      "step": 103
    },
    {
      "epoch": 0.104,
      "grad_norm": 7.178750991821289,
      "learning_rate": 4.4800000000000005e-05,
      "loss": 0.0598,
      "step": 104
    },
    {
      "epoch": 0.105,
      "grad_norm": 13.141042709350586,
      "learning_rate": 4.4750000000000004e-05,
      "loss": 0.0712,
      "step": 105
    },
    {
      "epoch": 0.106,
      "grad_norm": 31.1523494720459,
      "learning_rate": 4.47e-05,
      "loss": 0.1198,
      "step": 106
    },
    {
      "epoch": 0.107,
      "grad_norm": 0.059900905936956406,
      "learning_rate": 4.465e-05,
      "loss": 0.0013,
      "step": 107
    },
    {
      "epoch": 0.108,
      "grad_norm": 0.15931721031665802,
      "learning_rate": 4.46e-05,
      "loss": 0.0022,
      "step": 108
    },
    {
      "epoch": 0.109,
      "grad_norm": 0.19155970215797424,
      "learning_rate": 4.4550000000000005e-05,
      "loss": 0.0031,
      "step": 109
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.10165522992610931,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 0.0016,
      "step": 110
    },
    {
      "epoch": 0.111,
      "grad_norm": 3.9966142177581787,
      "learning_rate": 4.445e-05,
      "loss": 0.0271,
      "step": 111
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.06854213774204254,
      "learning_rate": 4.44e-05,
      "loss": 0.001,
      "step": 112
    },
    {
      "epoch": 0.113,
      "grad_norm": 0.3396826982498169,
      "learning_rate": 4.435e-05,
      "loss": 0.0052,
      "step": 113
    },
    {
      "epoch": 0.114,
      "grad_norm": 0.061477817595005035,
      "learning_rate": 4.43e-05,
      "loss": 0.0012,
      "step": 114
    },
    {
      "epoch": 0.115,
      "grad_norm": 1.5923590660095215,
      "learning_rate": 4.4250000000000005e-05,
      "loss": 0.0126,
      "step": 115
    },
    {
      "epoch": 0.116,
      "grad_norm": 0.23109783232212067,
      "learning_rate": 4.4200000000000004e-05,
      "loss": 0.0017,
      "step": 116
    },
    {
      "epoch": 0.117,
      "grad_norm": 0.22109591960906982,
      "learning_rate": 4.415e-05,
      "loss": 0.0026,
      "step": 117
    },
    {
      "epoch": 0.118,
      "grad_norm": 0.02963835373520851,
      "learning_rate": 4.41e-05,
      "loss": 0.0006,
      "step": 118
    },
    {
      "epoch": 0.119,
      "grad_norm": 0.033440861850976944,
      "learning_rate": 4.405e-05,
      "loss": 0.0008,
      "step": 119
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7981144189834595,
      "learning_rate": 4.4000000000000006e-05,
      "loss": 0.0083,
      "step": 120
    },
    {
      "epoch": 0.121,
      "grad_norm": 0.024660371243953705,
      "learning_rate": 4.3950000000000004e-05,
      "loss": 0.0003,
      "step": 121
    },
    {
      "epoch": 0.122,
      "grad_norm": 0.04533310979604721,
      "learning_rate": 4.39e-05,
      "loss": 0.0012,
      "step": 122
    },
    {
      "epoch": 0.123,
      "grad_norm": 0.34602800011634827,
      "learning_rate": 4.385e-05,
      "loss": 0.0047,
      "step": 123
    },
    {
      "epoch": 0.124,
      "grad_norm": 2.370945453643799,
      "learning_rate": 4.38e-05,
      "loss": 0.0384,
      "step": 124
    },
    {
      "epoch": 0.125,
      "grad_norm": 0.09401757270097733,
      "learning_rate": 4.375e-05,
      "loss": 0.002,
      "step": 125
    },
    {
      "epoch": 0.126,
      "grad_norm": 1.2105767726898193,
      "learning_rate": 4.3700000000000005e-05,
      "loss": 0.0173,
      "step": 126
    },
    {
      "epoch": 0.127,
      "grad_norm": 0.08835474401712418,
      "learning_rate": 4.3650000000000004e-05,
      "loss": 0.0018,
      "step": 127
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.12933948636054993,
      "learning_rate": 4.36e-05,
      "loss": 0.0015,
      "step": 128
    },
    {
      "epoch": 0.129,
      "grad_norm": 0.5954806804656982,
      "learning_rate": 4.355e-05,
      "loss": 0.0079,
      "step": 129
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.23991869390010834,
      "learning_rate": 4.35e-05,
      "loss": 0.0031,
      "step": 130
    },
    {
      "epoch": 0.131,
      "grad_norm": 0.29310348629951477,
      "learning_rate": 4.345e-05,
      "loss": 0.0029,
      "step": 131
    },
    {
      "epoch": 0.132,
      "grad_norm": 0.04956410825252533,
      "learning_rate": 4.3400000000000005e-05,
      "loss": 0.0007,
      "step": 132
    },
    {
      "epoch": 0.133,
      "grad_norm": 0.1937524378299713,
      "learning_rate": 4.335e-05,
      "loss": 0.0038,
      "step": 133
    },
    {
      "epoch": 0.134,
      "grad_norm": 0.05643218755722046,
      "learning_rate": 4.33e-05,
      "loss": 0.0008,
      "step": 134
    },
    {
      "epoch": 0.135,
      "grad_norm": 0.055229708552360535,
      "learning_rate": 4.325e-05,
      "loss": 0.0008,
      "step": 135
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.08144010603427887,
      "learning_rate": 4.32e-05,
      "loss": 0.0008,
      "step": 136
    },
    {
      "epoch": 0.137,
      "grad_norm": 0.4747541546821594,
      "learning_rate": 4.315e-05,
      "loss": 0.0076,
      "step": 137
    },
    {
      "epoch": 0.138,
      "grad_norm": 0.9820817708969116,
      "learning_rate": 4.3100000000000004e-05,
      "loss": 0.0111,
      "step": 138
    },
    {
      "epoch": 0.139,
      "grad_norm": 0.2812395989894867,
      "learning_rate": 4.305e-05,
      "loss": 0.0038,
      "step": 139
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.26322823762893677,
      "learning_rate": 4.3e-05,
      "loss": 0.0027,
      "step": 140
    },
    {
      "epoch": 0.141,
      "grad_norm": 0.607374370098114,
      "learning_rate": 4.295e-05,
      "loss": 0.0033,
      "step": 141
    },
    {
      "epoch": 0.142,
      "grad_norm": 0.4460834264755249,
      "learning_rate": 4.29e-05,
      "loss": 0.0049,
      "step": 142
    },
    {
      "epoch": 0.143,
      "grad_norm": 0.12947846949100494,
      "learning_rate": 4.285e-05,
      "loss": 0.0026,
      "step": 143
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.03393992409110069,
      "learning_rate": 4.2800000000000004e-05,
      "loss": 0.0005,
      "step": 144
    },
    {
      "epoch": 0.145,
      "grad_norm": 0.10068264603614807,
      "learning_rate": 4.275e-05,
      "loss": 0.002,
      "step": 145
    },
    {
      "epoch": 0.146,
      "grad_norm": 0.6265596151351929,
      "learning_rate": 4.27e-05,
      "loss": 0.0056,
      "step": 146
    },
    {
      "epoch": 0.147,
      "grad_norm": 5.953290939331055,
      "learning_rate": 4.265e-05,
      "loss": 0.0507,
      "step": 147
    },
    {
      "epoch": 0.148,
      "grad_norm": 0.0410950742661953,
      "learning_rate": 4.26e-05,
      "loss": 0.0008,
      "step": 148
    },
    {
      "epoch": 0.149,
      "grad_norm": 0.20164242386817932,
      "learning_rate": 4.2550000000000004e-05,
      "loss": 0.0027,
      "step": 149
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.279360830783844,
      "learning_rate": 4.25e-05,
      "loss": 0.0021,
      "step": 150
    },
    {
      "epoch": 0.151,
      "grad_norm": 0.5795413255691528,
      "learning_rate": 4.245e-05,
      "loss": 0.0109,
      "step": 151
    },
    {
      "epoch": 0.152,
      "grad_norm": 1.3455891609191895,
      "learning_rate": 4.24e-05,
      "loss": 0.0127,
      "step": 152
    },
    {
      "epoch": 0.153,
      "grad_norm": 1.585750699043274,
      "learning_rate": 4.235e-05,
      "loss": 0.022,
      "step": 153
    },
    {
      "epoch": 0.154,
      "grad_norm": 2.448456048965454,
      "learning_rate": 4.23e-05,
      "loss": 0.0253,
      "step": 154
    },
    {
      "epoch": 0.155,
      "grad_norm": 0.036019038408994675,
      "learning_rate": 4.2250000000000004e-05,
      "loss": 0.0003,
      "step": 155
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.32517293095588684,
      "learning_rate": 4.22e-05,
      "loss": 0.0038,
      "step": 156
    },
    {
      "epoch": 0.157,
      "grad_norm": 0.6427002549171448,
      "learning_rate": 4.215e-05,
      "loss": 0.0027,
      "step": 157
    },
    {
      "epoch": 0.158,
      "grad_norm": 0.21845711767673492,
      "learning_rate": 4.21e-05,
      "loss": 0.0047,
      "step": 158
    },
    {
      "epoch": 0.159,
      "grad_norm": 0.11761491745710373,
      "learning_rate": 4.205e-05,
      "loss": 0.0007,
      "step": 159
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.48081982135772705,
      "learning_rate": 4.2e-05,
      "loss": 0.0097,
      "step": 160
    },
    {
      "epoch": 0.161,
      "grad_norm": 0.009377969428896904,
      "learning_rate": 4.195e-05,
      "loss": 0.0002,
      "step": 161
    },
    {
      "epoch": 0.162,
      "grad_norm": 0.18237262964248657,
      "learning_rate": 4.19e-05,
      "loss": 0.0036,
      "step": 162
    },
    {
      "epoch": 0.163,
      "grad_norm": 0.20602644979953766,
      "learning_rate": 4.185e-05,
      "loss": 0.0036,
      "step": 163
    },
    {
      "epoch": 0.164,
      "grad_norm": 58.74104690551758,
      "learning_rate": 4.18e-05,
      "loss": 0.5911,
      "step": 164
    },
    {
      "epoch": 0.165,
      "grad_norm": 0.01897606812417507,
      "learning_rate": 4.175e-05,
      "loss": 0.0003,
      "step": 165
    },
    {
      "epoch": 0.166,
      "grad_norm": 0.39994579553604126,
      "learning_rate": 4.17e-05,
      "loss": 0.0054,
      "step": 166
    },
    {
      "epoch": 0.167,
      "grad_norm": 0.1782568097114563,
      "learning_rate": 4.165e-05,
      "loss": 0.0019,
      "step": 167
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.0316435880959034,
      "learning_rate": 4.16e-05,
      "loss": 0.0006,
      "step": 168
    },
    {
      "epoch": 0.169,
      "grad_norm": 0.12020616978406906,
      "learning_rate": 4.155e-05,
      "loss": 0.0025,
      "step": 169
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.08447874337434769,
      "learning_rate": 4.15e-05,
      "loss": 0.0008,
      "step": 170
    },
    {
      "epoch": 0.171,
      "grad_norm": 0.4380529224872589,
      "learning_rate": 4.145e-05,
      "loss": 0.0062,
      "step": 171
    },
    {
      "epoch": 0.172,
      "grad_norm": 0.8025440573692322,
      "learning_rate": 4.14e-05,
      "loss": 0.0091,
      "step": 172
    },
    {
      "epoch": 0.173,
      "grad_norm": 0.19414325058460236,
      "learning_rate": 4.135e-05,
      "loss": 0.0045,
      "step": 173
    },
    {
      "epoch": 0.174,
      "grad_norm": 0.06393507868051529,
      "learning_rate": 4.13e-05,
      "loss": 0.0018,
      "step": 174
    },
    {
      "epoch": 0.175,
      "grad_norm": 0.019550947472453117,
      "learning_rate": 4.125e-05,
      "loss": 0.0003,
      "step": 175
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.028763189911842346,
      "learning_rate": 4.12e-05,
      "loss": 0.0005,
      "step": 176
    },
    {
      "epoch": 0.177,
      "grad_norm": 0.1501455456018448,
      "learning_rate": 4.115e-05,
      "loss": 0.0016,
      "step": 177
    },
    {
      "epoch": 0.178,
      "grad_norm": 1.3664026260375977,
      "learning_rate": 4.11e-05,
      "loss": 0.0158,
      "step": 178
    },
    {
      "epoch": 0.179,
      "grad_norm": 0.2654472291469574,
      "learning_rate": 4.105e-05,
      "loss": 0.0033,
      "step": 179
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.04249381646513939,
      "learning_rate": 4.1e-05,
      "loss": 0.001,
      "step": 180
    },
    {
      "epoch": 0.181,
      "grad_norm": 0.02758362889289856,
      "learning_rate": 4.095e-05,
      "loss": 0.0005,
      "step": 181
    },
    {
      "epoch": 0.182,
      "grad_norm": 0.019895967096090317,
      "learning_rate": 4.09e-05,
      "loss": 0.0003,
      "step": 182
    },
    {
      "epoch": 0.183,
      "grad_norm": 0.006930613424628973,
      "learning_rate": 4.085e-05,
      "loss": 0.0001,
      "step": 183
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.07593825459480286,
      "learning_rate": 4.08e-05,
      "loss": 0.001,
      "step": 184
    },
    {
      "epoch": 0.185,
      "grad_norm": 0.9518314003944397,
      "learning_rate": 4.075e-05,
      "loss": 0.0076,
      "step": 185
    },
    {
      "epoch": 0.186,
      "grad_norm": 0.03384218364953995,
      "learning_rate": 4.07e-05,
      "loss": 0.0006,
      "step": 186
    },
    {
      "epoch": 0.187,
      "grad_norm": 0.06786356121301651,
      "learning_rate": 4.065e-05,
      "loss": 0.001,
      "step": 187
    },
    {
      "epoch": 0.188,
      "grad_norm": 1.4707274436950684,
      "learning_rate": 4.0600000000000004e-05,
      "loss": 0.0119,
      "step": 188
    },
    {
      "epoch": 0.189,
      "grad_norm": 0.1572292000055313,
      "learning_rate": 4.055e-05,
      "loss": 0.002,
      "step": 189
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.4769848585128784,
      "learning_rate": 4.05e-05,
      "loss": 0.0142,
      "step": 190
    },
    {
      "epoch": 0.191,
      "grad_norm": 0.5167664289474487,
      "learning_rate": 4.045000000000001e-05,
      "loss": 0.0055,
      "step": 191
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.10221054404973984,
      "learning_rate": 4.0400000000000006e-05,
      "loss": 0.0019,
      "step": 192
    },
    {
      "epoch": 0.193,
      "grad_norm": 0.23805180191993713,
      "learning_rate": 4.0350000000000005e-05,
      "loss": 0.0034,
      "step": 193
    },
    {
      "epoch": 0.194,
      "grad_norm": 0.05835342779755592,
      "learning_rate": 4.0300000000000004e-05,
      "loss": 0.0012,
      "step": 194
    },
    {
      "epoch": 0.195,
      "grad_norm": 2.937040328979492,
      "learning_rate": 4.025e-05,
      "loss": 0.0342,
      "step": 195
    },
    {
      "epoch": 0.196,
      "grad_norm": 0.40491983294487,
      "learning_rate": 4.02e-05,
      "loss": 0.0067,
      "step": 196
    },
    {
      "epoch": 0.197,
      "grad_norm": 0.8067626953125,
      "learning_rate": 4.015000000000001e-05,
      "loss": 0.0089,
      "step": 197
    },
    {
      "epoch": 0.198,
      "grad_norm": 0.1996677964925766,
      "learning_rate": 4.0100000000000006e-05,
      "loss": 0.0014,
      "step": 198
    },
    {
      "epoch": 0.199,
      "grad_norm": 0.46734172105789185,
      "learning_rate": 4.0050000000000004e-05,
      "loss": 0.0102,
      "step": 199
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.0313936248421669,
      "learning_rate": 4e-05,
      "loss": 0.0005,
      "step": 200
    },
    {
      "epoch": 0.201,
      "grad_norm": 15.4666166305542,
      "learning_rate": 3.995e-05,
      "loss": 1.5295,
      "step": 201
    },
    {
      "epoch": 0.202,
      "grad_norm": 0.09144671261310577,
      "learning_rate": 3.99e-05,
      "loss": 0.0019,
      "step": 202
    },
    {
      "epoch": 0.203,
      "grad_norm": 1.058518886566162,
      "learning_rate": 3.9850000000000006e-05,
      "loss": 0.0086,
      "step": 203
    },
    {
      "epoch": 0.204,
      "grad_norm": 0.07424719631671906,
      "learning_rate": 3.9800000000000005e-05,
      "loss": 0.001,
      "step": 204
    },
    {
      "epoch": 0.205,
      "grad_norm": 0.013834364712238312,
      "learning_rate": 3.9750000000000004e-05,
      "loss": 0.0003,
      "step": 205
    },
    {
      "epoch": 0.206,
      "grad_norm": 1.7751576900482178,
      "learning_rate": 3.97e-05,
      "loss": 0.0104,
      "step": 206
    },
    {
      "epoch": 0.207,
      "grad_norm": 0.01759530045092106,
      "learning_rate": 3.965e-05,
      "loss": 0.0004,
      "step": 207
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.053059183061122894,
      "learning_rate": 3.960000000000001e-05,
      "loss": 0.0008,
      "step": 208
    },
    {
      "epoch": 0.209,
      "grad_norm": 0.33660244941711426,
      "learning_rate": 3.9550000000000006e-05,
      "loss": 0.0031,
      "step": 209
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.17786847054958344,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 0.0025,
      "step": 210
    },
    {
      "epoch": 0.211,
      "grad_norm": 0.06909053772687912,
      "learning_rate": 3.9450000000000003e-05,
      "loss": 0.0009,
      "step": 211
    },
    {
      "epoch": 0.212,
      "grad_norm": 0.7514475584030151,
      "learning_rate": 3.94e-05,
      "loss": 0.0037,
      "step": 212
    },
    {
      "epoch": 0.213,
      "grad_norm": 0.03524206578731537,
      "learning_rate": 3.935e-05,
      "loss": 0.0005,
      "step": 213
    },
    {
      "epoch": 0.214,
      "grad_norm": 0.16363829374313354,
      "learning_rate": 3.9300000000000007e-05,
      "loss": 0.0019,
      "step": 214
    },
    {
      "epoch": 0.215,
      "grad_norm": 0.008879650384187698,
      "learning_rate": 3.9250000000000005e-05,
      "loss": 0.0002,
      "step": 215
    },
    {
      "epoch": 0.216,
      "grad_norm": 4.174769401550293,
      "learning_rate": 3.9200000000000004e-05,
      "loss": 0.0145,
      "step": 216
    },
    {
      "epoch": 0.217,
      "grad_norm": 0.00746532017365098,
      "learning_rate": 3.915e-05,
      "loss": 0.0002,
      "step": 217
    },
    {
      "epoch": 0.218,
      "grad_norm": 0.07319726794958115,
      "learning_rate": 3.91e-05,
      "loss": 0.0013,
      "step": 218
    },
    {
      "epoch": 0.219,
      "grad_norm": 0.2376372367143631,
      "learning_rate": 3.905e-05,
      "loss": 0.0047,
      "step": 219
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.008743165992200375,
      "learning_rate": 3.9000000000000006e-05,
      "loss": 0.0002,
      "step": 220
    },
    {
      "epoch": 0.221,
      "grad_norm": 0.2904977798461914,
      "learning_rate": 3.8950000000000005e-05,
      "loss": 0.0022,
      "step": 221
    },
    {
      "epoch": 0.222,
      "grad_norm": 0.00764997536316514,
      "learning_rate": 3.8900000000000004e-05,
      "loss": 0.0001,
      "step": 222
    },
    {
      "epoch": 0.223,
      "grad_norm": 0.05411684885621071,
      "learning_rate": 3.885e-05,
      "loss": 0.0004,
      "step": 223
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.1408514827489853,
      "learning_rate": 3.88e-05,
      "loss": 0.0025,
      "step": 224
    },
    {
      "epoch": 0.225,
      "grad_norm": 0.0448409840464592,
      "learning_rate": 3.875e-05,
      "loss": 0.0007,
      "step": 225
    },
    {
      "epoch": 0.226,
      "grad_norm": 0.005330965854227543,
      "learning_rate": 3.8700000000000006e-05,
      "loss": 0.0001,
      "step": 226
    },
    {
      "epoch": 0.227,
      "grad_norm": 0.20012953877449036,
      "learning_rate": 3.8650000000000004e-05,
      "loss": 0.0026,
      "step": 227
    },
    {
      "epoch": 0.228,
      "grad_norm": 0.1405719369649887,
      "learning_rate": 3.86e-05,
      "loss": 0.002,
      "step": 228
    },
    {
      "epoch": 0.229,
      "grad_norm": 0.10699345171451569,
      "learning_rate": 3.855e-05,
      "loss": 0.0016,
      "step": 229
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.11467590928077698,
      "learning_rate": 3.85e-05,
      "loss": 0.0019,
      "step": 230
    },
    {
      "epoch": 0.231,
      "grad_norm": 0.166453018784523,
      "learning_rate": 3.845e-05,
      "loss": 0.0034,
      "step": 231
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.10765417665243149,
      "learning_rate": 3.8400000000000005e-05,
      "loss": 0.0008,
      "step": 232
    },
    {
      "epoch": 0.233,
      "grad_norm": 0.06457780301570892,
      "learning_rate": 3.8350000000000004e-05,
      "loss": 0.001,
      "step": 233
    },
    {
      "epoch": 0.234,
      "grad_norm": 0.18466836214065552,
      "learning_rate": 3.83e-05,
      "loss": 0.0024,
      "step": 234
    },
    {
      "epoch": 0.235,
      "grad_norm": 0.004332073498517275,
      "learning_rate": 3.825e-05,
      "loss": 0.0001,
      "step": 235
    },
    {
      "epoch": 0.236,
      "grad_norm": 0.06504493951797485,
      "learning_rate": 3.82e-05,
      "loss": 0.0012,
      "step": 236
    },
    {
      "epoch": 0.237,
      "grad_norm": 0.05467769503593445,
      "learning_rate": 3.8150000000000006e-05,
      "loss": 0.0008,
      "step": 237
    },
    {
      "epoch": 0.238,
      "grad_norm": 0.16634760797023773,
      "learning_rate": 3.8100000000000005e-05,
      "loss": 0.0035,
      "step": 238
    },
    {
      "epoch": 0.239,
      "grad_norm": 0.3953906297683716,
      "learning_rate": 3.805e-05,
      "loss": 0.0027,
      "step": 239
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.005496685393154621,
      "learning_rate": 3.8e-05,
      "loss": 0.0001,
      "step": 240
    },
    {
      "epoch": 0.241,
      "grad_norm": 0.08130864799022675,
      "learning_rate": 3.795e-05,
      "loss": 0.0011,
      "step": 241
    },
    {
      "epoch": 0.242,
      "grad_norm": 0.11700309067964554,
      "learning_rate": 3.79e-05,
      "loss": 0.0021,
      "step": 242
    },
    {
      "epoch": 0.243,
      "grad_norm": 0.0675681084394455,
      "learning_rate": 3.7850000000000005e-05,
      "loss": 0.001,
      "step": 243
    },
    {
      "epoch": 0.244,
      "grad_norm": 0.0071281627751886845,
      "learning_rate": 3.7800000000000004e-05,
      "loss": 0.0001,
      "step": 244
    },
    {
      "epoch": 0.245,
      "grad_norm": 0.009707827121019363,
      "learning_rate": 3.775e-05,
      "loss": 0.0002,
      "step": 245
    },
    {
      "epoch": 0.246,
      "grad_norm": 0.1039251983165741,
      "learning_rate": 3.77e-05,
      "loss": 0.0011,
      "step": 246
    },
    {
      "epoch": 0.247,
      "grad_norm": 0.13484783470630646,
      "learning_rate": 3.765e-05,
      "loss": 0.0011,
      "step": 247
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.2845415472984314,
      "learning_rate": 3.76e-05,
      "loss": 0.0038,
      "step": 248
    },
    {
      "epoch": 0.249,
      "grad_norm": 0.02934098243713379,
      "learning_rate": 3.7550000000000005e-05,
      "loss": 0.0006,
      "step": 249
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.0913766548037529,
      "learning_rate": 3.7500000000000003e-05,
      "loss": 0.0009,
      "step": 250
    },
    {
      "epoch": 0.251,
      "grad_norm": 0.13192108273506165,
      "learning_rate": 3.745e-05,
      "loss": 0.0026,
      "step": 251
    },
    {
      "epoch": 0.252,
      "grad_norm": 0.020647935569286346,
      "learning_rate": 3.74e-05,
      "loss": 0.0004,
      "step": 252
    },
    {
      "epoch": 0.253,
      "grad_norm": 0.15335778892040253,
      "learning_rate": 3.735e-05,
      "loss": 0.0026,
      "step": 253
    },
    {
      "epoch": 0.254,
      "grad_norm": 0.05950933322310448,
      "learning_rate": 3.73e-05,
      "loss": 0.0005,
      "step": 254
    },
    {
      "epoch": 0.255,
      "grad_norm": 0.06618266552686691,
      "learning_rate": 3.7250000000000004e-05,
      "loss": 0.0009,
      "step": 255
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.016686568036675453,
      "learning_rate": 3.72e-05,
      "loss": 0.0003,
      "step": 256
    },
    {
      "epoch": 0.257,
      "grad_norm": 0.01974935084581375,
      "learning_rate": 3.715e-05,
      "loss": 0.0004,
      "step": 257
    },
    {
      "epoch": 0.258,
      "grad_norm": 0.008361464366316795,
      "learning_rate": 3.71e-05,
      "loss": 0.0001,
      "step": 258
    },
    {
      "epoch": 0.259,
      "grad_norm": 0.02437782846391201,
      "learning_rate": 3.705e-05,
      "loss": 0.0006,
      "step": 259
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.01834067888557911,
      "learning_rate": 3.7e-05,
      "loss": 0.0003,
      "step": 260
    },
    {
      "epoch": 0.261,
      "grad_norm": 0.07455664128065109,
      "learning_rate": 3.6950000000000004e-05,
      "loss": 0.0012,
      "step": 261
    },
    {
      "epoch": 0.262,
      "grad_norm": 0.2303062379360199,
      "learning_rate": 3.69e-05,
      "loss": 0.0033,
      "step": 262
    },
    {
      "epoch": 0.263,
      "grad_norm": 0.43690162897109985,
      "learning_rate": 3.685e-05,
      "loss": 0.0018,
      "step": 263
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.015577333979308605,
      "learning_rate": 3.68e-05,
      "loss": 0.0004,
      "step": 264
    },
    {
      "epoch": 0.265,
      "grad_norm": 0.24250571429729462,
      "learning_rate": 3.675e-05,
      "loss": 0.0042,
      "step": 265
    },
    {
      "epoch": 0.266,
      "grad_norm": 0.28250652551651,
      "learning_rate": 3.6700000000000004e-05,
      "loss": 0.003,
      "step": 266
    },
    {
      "epoch": 0.267,
      "grad_norm": 0.05005941540002823,
      "learning_rate": 3.665e-05,
      "loss": 0.0005,
      "step": 267
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.06150428205728531,
      "learning_rate": 3.66e-05,
      "loss": 0.0009,
      "step": 268
    },
    {
      "epoch": 0.269,
      "grad_norm": 0.023624282330274582,
      "learning_rate": 3.655e-05,
      "loss": 0.0002,
      "step": 269
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.026790780946612358,
      "learning_rate": 3.65e-05,
      "loss": 0.0004,
      "step": 270
    },
    {
      "epoch": 0.271,
      "grad_norm": 0.08135806769132614,
      "learning_rate": 3.645e-05,
      "loss": 0.0015,
      "step": 271
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.09818751364946365,
      "learning_rate": 3.6400000000000004e-05,
      "loss": 0.0009,
      "step": 272
    },
    {
      "epoch": 0.273,
      "grad_norm": 0.010227150283753872,
      "learning_rate": 3.635e-05,
      "loss": 0.0002,
      "step": 273
    },
    {
      "epoch": 0.274,
      "grad_norm": 0.021803025156259537,
      "learning_rate": 3.63e-05,
      "loss": 0.0004,
      "step": 274
    },
    {
      "epoch": 0.275,
      "grad_norm": 0.1289750635623932,
      "learning_rate": 3.625e-05,
      "loss": 0.0022,
      "step": 275
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.12066281586885452,
      "learning_rate": 3.62e-05,
      "loss": 0.002,
      "step": 276
    },
    {
      "epoch": 0.277,
      "grad_norm": 0.19426202774047852,
      "learning_rate": 3.615e-05,
      "loss": 0.0023,
      "step": 277
    },
    {
      "epoch": 0.278,
      "grad_norm": 0.05482945591211319,
      "learning_rate": 3.61e-05,
      "loss": 0.0006,
      "step": 278
    },
    {
      "epoch": 0.279,
      "grad_norm": 0.03831174224615097,
      "learning_rate": 3.605e-05,
      "loss": 0.0008,
      "step": 279
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.007526618894189596,
      "learning_rate": 3.6e-05,
      "loss": 0.0001,
      "step": 280
    },
    {
      "epoch": 0.281,
      "grad_norm": 0.11903434246778488,
      "learning_rate": 3.595e-05,
      "loss": 0.0013,
      "step": 281
    },
    {
      "epoch": 0.282,
      "grad_norm": 0.59787917137146,
      "learning_rate": 3.59e-05,
      "loss": 0.0035,
      "step": 282
    },
    {
      "epoch": 0.283,
      "grad_norm": 0.35015541315078735,
      "learning_rate": 3.585e-05,
      "loss": 0.0041,
      "step": 283
    },
    {
      "epoch": 0.284,
      "grad_norm": 0.22242647409439087,
      "learning_rate": 3.58e-05,
      "loss": 0.0024,
      "step": 284
    },
    {
      "epoch": 0.285,
      "grad_norm": 0.7184547185897827,
      "learning_rate": 3.575e-05,
      "loss": 0.011,
      "step": 285
    },
    {
      "epoch": 0.286,
      "grad_norm": 0.4307844340801239,
      "learning_rate": 3.57e-05,
      "loss": 0.0063,
      "step": 286
    },
    {
      "epoch": 0.287,
      "grad_norm": 0.15655021369457245,
      "learning_rate": 3.565e-05,
      "loss": 0.0003,
      "step": 287
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.034271832555532455,
      "learning_rate": 3.56e-05,
      "loss": 0.0003,
      "step": 288
    },
    {
      "epoch": 0.289,
      "grad_norm": 0.2727739214897156,
      "learning_rate": 3.555e-05,
      "loss": 0.0043,
      "step": 289
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.005313380621373653,
      "learning_rate": 3.55e-05,
      "loss": 0.0001,
      "step": 290
    },
    {
      "epoch": 0.291,
      "grad_norm": 0.09656790643930435,
      "learning_rate": 3.545e-05,
      "loss": 0.0013,
      "step": 291
    },
    {
      "epoch": 0.292,
      "grad_norm": 0.0318460650742054,
      "learning_rate": 3.54e-05,
      "loss": 0.0006,
      "step": 292
    },
    {
      "epoch": 0.293,
      "grad_norm": 0.06763770431280136,
      "learning_rate": 3.535e-05,
      "loss": 0.0009,
      "step": 293
    },
    {
      "epoch": 0.294,
      "grad_norm": 0.20331275463104248,
      "learning_rate": 3.53e-05,
      "loss": 0.0018,
      "step": 294
    },
    {
      "epoch": 0.295,
      "grad_norm": 0.14279122650623322,
      "learning_rate": 3.525e-05,
      "loss": 0.0017,
      "step": 295
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.2635306119918823,
      "learning_rate": 3.52e-05,
      "loss": 0.0031,
      "step": 296
    },
    {
      "epoch": 0.297,
      "grad_norm": 5.945153713226318,
      "learning_rate": 3.515e-05,
      "loss": 0.053,
      "step": 297
    },
    {
      "epoch": 0.298,
      "grad_norm": 0.052702032029628754,
      "learning_rate": 3.51e-05,
      "loss": 0.0006,
      "step": 298
    },
    {
      "epoch": 0.299,
      "grad_norm": 0.08760135620832443,
      "learning_rate": 3.505e-05,
      "loss": 0.0017,
      "step": 299
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.03187806159257889,
      "learning_rate": 3.5e-05,
      "loss": 0.0004,
      "step": 300
    },
    {
      "epoch": 0.301,
      "grad_norm": 0.049367714673280716,
      "learning_rate": 3.495e-05,
      "loss": 0.0006,
      "step": 301
    },
    {
      "epoch": 0.302,
      "grad_norm": 0.47472715377807617,
      "learning_rate": 3.49e-05,
      "loss": 0.0074,
      "step": 302
    },
    {
      "epoch": 0.303,
      "grad_norm": 0.048847731202840805,
      "learning_rate": 3.485e-05,
      "loss": 0.0007,
      "step": 303
    },
    {
      "epoch": 0.304,
      "grad_norm": 8.147526741027832,
      "learning_rate": 3.48e-05,
      "loss": 0.0295,
      "step": 304
    },
    {
      "epoch": 0.305,
      "grad_norm": 0.02025112509727478,
      "learning_rate": 3.475e-05,
      "loss": 0.0002,
      "step": 305
    },
    {
      "epoch": 0.306,
      "grad_norm": 0.031803030520677567,
      "learning_rate": 3.4699999999999996e-05,
      "loss": 0.0005,
      "step": 306
    },
    {
      "epoch": 0.307,
      "grad_norm": 0.023015012964606285,
      "learning_rate": 3.465e-05,
      "loss": 0.0003,
      "step": 307
    },
    {
      "epoch": 0.308,
      "grad_norm": 0.18441177904605865,
      "learning_rate": 3.46e-05,
      "loss": 0.0021,
      "step": 308
    },
    {
      "epoch": 0.309,
      "grad_norm": 0.04266710206866264,
      "learning_rate": 3.455e-05,
      "loss": 0.0009,
      "step": 309
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.028399627655744553,
      "learning_rate": 3.45e-05,
      "loss": 0.0003,
      "step": 310
    },
    {
      "epoch": 0.311,
      "grad_norm": 0.1857161670923233,
      "learning_rate": 3.445e-05,
      "loss": 0.0029,
      "step": 311
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.06593424826860428,
      "learning_rate": 3.4399999999999996e-05,
      "loss": 0.0006,
      "step": 312
    },
    {
      "epoch": 0.313,
      "grad_norm": 0.03340662270784378,
      "learning_rate": 3.435e-05,
      "loss": 0.0006,
      "step": 313
    },
    {
      "epoch": 0.314,
      "grad_norm": 0.0032857945188879967,
      "learning_rate": 3.430000000000001e-05,
      "loss": 0.0001,
      "step": 314
    },
    {
      "epoch": 0.315,
      "grad_norm": 0.04836833104491234,
      "learning_rate": 3.4250000000000006e-05,
      "loss": 0.0006,
      "step": 315
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.08219848573207855,
      "learning_rate": 3.4200000000000005e-05,
      "loss": 0.0006,
      "step": 316
    },
    {
      "epoch": 0.317,
      "grad_norm": 0.020781757310032845,
      "learning_rate": 3.415e-05,
      "loss": 0.0004,
      "step": 317
    },
    {
      "epoch": 0.318,
      "grad_norm": 0.05556083843111992,
      "learning_rate": 3.41e-05,
      "loss": 0.0007,
      "step": 318
    },
    {
      "epoch": 0.319,
      "grad_norm": 0.03190077096223831,
      "learning_rate": 3.405e-05,
      "loss": 0.0007,
      "step": 319
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.005220978520810604,
      "learning_rate": 3.4000000000000007e-05,
      "loss": 0.0001,
      "step": 320
    },
    {
      "epoch": 0.321,
      "grad_norm": 0.005711314734071493,
      "learning_rate": 3.3950000000000005e-05,
      "loss": 0.0001,
      "step": 321
    },
    {
      "epoch": 0.322,
      "grad_norm": 0.8921332359313965,
      "learning_rate": 3.3900000000000004e-05,
      "loss": 0.0044,
      "step": 322
    },
    {
      "epoch": 0.323,
      "grad_norm": 0.073616623878479,
      "learning_rate": 3.385e-05,
      "loss": 0.0009,
      "step": 323
    },
    {
      "epoch": 0.324,
      "grad_norm": 0.5282725095748901,
      "learning_rate": 3.38e-05,
      "loss": 0.0042,
      "step": 324
    },
    {
      "epoch": 0.325,
      "grad_norm": 0.1903732717037201,
      "learning_rate": 3.375000000000001e-05,
      "loss": 0.0033,
      "step": 325
    },
    {
      "epoch": 0.326,
      "grad_norm": 0.02446308359503746,
      "learning_rate": 3.3700000000000006e-05,
      "loss": 0.0005,
      "step": 326
    },
    {
      "epoch": 0.327,
      "grad_norm": 0.13265427947044373,
      "learning_rate": 3.3650000000000005e-05,
      "loss": 0.0012,
      "step": 327
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.050268031656742096,
      "learning_rate": 3.3600000000000004e-05,
      "loss": 0.001,
      "step": 328
    },
    {
      "epoch": 0.329,
      "grad_norm": 0.05204175412654877,
      "learning_rate": 3.355e-05,
      "loss": 0.0012,
      "step": 329
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.021414516493678093,
      "learning_rate": 3.35e-05,
      "loss": 0.0002,
      "step": 330
    },
    {
      "epoch": 0.331,
      "grad_norm": 0.031417347490787506,
      "learning_rate": 3.345000000000001e-05,
      "loss": 0.0008,
      "step": 331
    },
    {
      "epoch": 0.332,
      "grad_norm": 0.026272883638739586,
      "learning_rate": 3.3400000000000005e-05,
      "loss": 0.0003,
      "step": 332
    },
    {
      "epoch": 0.333,
      "grad_norm": 0.02554064430296421,
      "learning_rate": 3.3350000000000004e-05,
      "loss": 0.0005,
      "step": 333
    },
    {
      "epoch": 0.334,
      "grad_norm": 0.04314231872558594,
      "learning_rate": 3.33e-05,
      "loss": 0.0004,
      "step": 334
    },
    {
      "epoch": 0.335,
      "grad_norm": 0.1455276757478714,
      "learning_rate": 3.325e-05,
      "loss": 0.0013,
      "step": 335
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.035374730825424194,
      "learning_rate": 3.32e-05,
      "loss": 0.0005,
      "step": 336
    },
    {
      "epoch": 0.337,
      "grad_norm": 31.662668228149414,
      "learning_rate": 3.3150000000000006e-05,
      "loss": 0.1716,
      "step": 337
    },
    {
      "epoch": 0.338,
      "grad_norm": 0.14681212604045868,
      "learning_rate": 3.3100000000000005e-05,
      "loss": 0.0017,
      "step": 338
    },
    {
      "epoch": 0.339,
      "grad_norm": 0.1338554322719574,
      "learning_rate": 3.3050000000000004e-05,
      "loss": 0.001,
      "step": 339
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.017298923805356026,
      "learning_rate": 3.3e-05,
      "loss": 0.0003,
      "step": 340
    },
    {
      "epoch": 0.341,
      "grad_norm": 0.002785095712170005,
      "learning_rate": 3.295e-05,
      "loss": 0.0,
      "step": 341
    },
    {
      "epoch": 0.342,
      "grad_norm": 0.004735828842967749,
      "learning_rate": 3.29e-05,
      "loss": 0.0001,
      "step": 342
    },
    {
      "epoch": 0.343,
      "grad_norm": 0.026827659457921982,
      "learning_rate": 3.2850000000000006e-05,
      "loss": 0.0005,
      "step": 343
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.07278485596179962,
      "learning_rate": 3.2800000000000004e-05,
      "loss": 0.0011,
      "step": 344
    },
    {
      "epoch": 0.345,
      "grad_norm": 0.15496277809143066,
      "learning_rate": 3.275e-05,
      "loss": 0.0027,
      "step": 345
    },
    {
      "epoch": 0.346,
      "grad_norm": 0.02222743071615696,
      "learning_rate": 3.27e-05,
      "loss": 0.0005,
      "step": 346
    },
    {
      "epoch": 0.347,
      "grad_norm": 0.17294861376285553,
      "learning_rate": 3.265e-05,
      "loss": 0.0033,
      "step": 347
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.08088646829128265,
      "learning_rate": 3.26e-05,
      "loss": 0.0013,
      "step": 348
    },
    {
      "epoch": 0.349,
      "grad_norm": 0.06448572129011154,
      "learning_rate": 3.2550000000000005e-05,
      "loss": 0.001,
      "step": 349
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.004820489790290594,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.0001,
      "step": 350
    },
    {
      "epoch": 0.351,
      "grad_norm": 0.010499167256057262,
      "learning_rate": 3.245e-05,
      "loss": 0.0002,
      "step": 351
    },
    {
      "epoch": 0.352,
      "grad_norm": 1.1131691932678223,
      "learning_rate": 3.24e-05,
      "loss": 0.0164,
      "step": 352
    },
    {
      "epoch": 0.353,
      "grad_norm": 0.06782548874616623,
      "learning_rate": 3.235e-05,
      "loss": 0.0013,
      "step": 353
    },
    {
      "epoch": 0.354,
      "grad_norm": 0.2908705770969391,
      "learning_rate": 3.2300000000000006e-05,
      "loss": 0.0022,
      "step": 354
    },
    {
      "epoch": 0.355,
      "grad_norm": 0.004574049264192581,
      "learning_rate": 3.2250000000000005e-05,
      "loss": 0.0001,
      "step": 355
    },
    {
      "epoch": 0.356,
      "grad_norm": 0.2678469717502594,
      "learning_rate": 3.2200000000000003e-05,
      "loss": 0.0022,
      "step": 356
    },
    {
      "epoch": 0.357,
      "grad_norm": 0.08940199762582779,
      "learning_rate": 3.215e-05,
      "loss": 0.0014,
      "step": 357
    },
    {
      "epoch": 0.358,
      "grad_norm": 1.714245080947876,
      "learning_rate": 3.21e-05,
      "loss": 0.016,
      "step": 358
    },
    {
      "epoch": 0.359,
      "grad_norm": 0.001636708271689713,
      "learning_rate": 3.205e-05,
      "loss": 0.0,
      "step": 359
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.1280171275138855,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 0.0015,
      "step": 360
    },
    {
      "epoch": 0.361,
      "grad_norm": 0.06502441316843033,
      "learning_rate": 3.1950000000000004e-05,
      "loss": 0.0012,
      "step": 361
    },
    {
      "epoch": 0.362,
      "grad_norm": 0.08531983941793442,
      "learning_rate": 3.19e-05,
      "loss": 0.0015,
      "step": 362
    },
    {
      "epoch": 0.363,
      "grad_norm": 0.014258637093007565,
      "learning_rate": 3.185e-05,
      "loss": 0.0003,
      "step": 363
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.07281289249658585,
      "learning_rate": 3.18e-05,
      "loss": 0.0007,
      "step": 364
    },
    {
      "epoch": 0.365,
      "grad_norm": 0.022885089740157127,
      "learning_rate": 3.175e-05,
      "loss": 0.0005,
      "step": 365
    },
    {
      "epoch": 0.366,
      "grad_norm": 0.0019515196327120066,
      "learning_rate": 3.1700000000000005e-05,
      "loss": 0.0,
      "step": 366
    },
    {
      "epoch": 0.367,
      "grad_norm": 0.13312913477420807,
      "learning_rate": 3.1650000000000004e-05,
      "loss": 0.0013,
      "step": 367
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.1300508826971054,
      "learning_rate": 3.16e-05,
      "loss": 0.0012,
      "step": 368
    },
    {
      "epoch": 0.369,
      "grad_norm": 0.07561672478914261,
      "learning_rate": 3.155e-05,
      "loss": 0.0007,
      "step": 369
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.04881317913532257,
      "learning_rate": 3.15e-05,
      "loss": 0.0005,
      "step": 370
    },
    {
      "epoch": 0.371,
      "grad_norm": 0.8108437657356262,
      "learning_rate": 3.145e-05,
      "loss": 0.0078,
      "step": 371
    },
    {
      "epoch": 0.372,
      "grad_norm": 0.17529354989528656,
      "learning_rate": 3.1400000000000004e-05,
      "loss": 0.0017,
      "step": 372
    },
    {
      "epoch": 0.373,
      "grad_norm": 0.4328552186489105,
      "learning_rate": 3.135e-05,
      "loss": 0.0095,
      "step": 373
    },
    {
      "epoch": 0.374,
      "grad_norm": 0.02785179577767849,
      "learning_rate": 3.13e-05,
      "loss": 0.0004,
      "step": 374
    },
    {
      "epoch": 0.375,
      "grad_norm": 0.01781338080763817,
      "learning_rate": 3.125e-05,
      "loss": 0.0003,
      "step": 375
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.007343745790421963,
      "learning_rate": 3.12e-05,
      "loss": 0.0001,
      "step": 376
    },
    {
      "epoch": 0.377,
      "grad_norm": 0.22051458060741425,
      "learning_rate": 3.115e-05,
      "loss": 0.0024,
      "step": 377
    },
    {
      "epoch": 0.378,
      "grad_norm": 0.006636874750256538,
      "learning_rate": 3.1100000000000004e-05,
      "loss": 0.0001,
      "step": 378
    },
    {
      "epoch": 0.379,
      "grad_norm": 0.009172443300485611,
      "learning_rate": 3.105e-05,
      "loss": 0.0002,
      "step": 379
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.7038111090660095,
      "learning_rate": 3.1e-05,
      "loss": 0.0091,
      "step": 380
    },
    {
      "epoch": 0.381,
      "grad_norm": 0.10530006885528564,
      "learning_rate": 3.095e-05,
      "loss": 0.0023,
      "step": 381
    },
    {
      "epoch": 0.382,
      "grad_norm": 0.021738162264227867,
      "learning_rate": 3.09e-05,
      "loss": 0.0004,
      "step": 382
    },
    {
      "epoch": 0.383,
      "grad_norm": 0.07823747396469116,
      "learning_rate": 3.0850000000000004e-05,
      "loss": 0.0011,
      "step": 383
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.03685637190937996,
      "learning_rate": 3.08e-05,
      "loss": 0.0008,
      "step": 384
    },
    {
      "epoch": 0.385,
      "grad_norm": 0.014635654166340828,
      "learning_rate": 3.075e-05,
      "loss": 0.0002,
      "step": 385
    },
    {
      "epoch": 0.386,
      "grad_norm": 0.019658688455820084,
      "learning_rate": 3.07e-05,
      "loss": 0.0002,
      "step": 386
    },
    {
      "epoch": 0.387,
      "grad_norm": 0.07859183102846146,
      "learning_rate": 3.065e-05,
      "loss": 0.0013,
      "step": 387
    },
    {
      "epoch": 0.388,
      "grad_norm": 0.20117400586605072,
      "learning_rate": 3.06e-05,
      "loss": 0.0029,
      "step": 388
    },
    {
      "epoch": 0.389,
      "grad_norm": 0.6385700702667236,
      "learning_rate": 3.0550000000000004e-05,
      "loss": 0.0021,
      "step": 389
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.022581949830055237,
      "learning_rate": 3.05e-05,
      "loss": 0.0004,
      "step": 390
    },
    {
      "epoch": 0.391,
      "grad_norm": 0.30587854981422424,
      "learning_rate": 3.045e-05,
      "loss": 0.0037,
      "step": 391
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.042246073484420776,
      "learning_rate": 3.04e-05,
      "loss": 0.0009,
      "step": 392
    },
    {
      "epoch": 0.393,
      "grad_norm": 0.09826482087373734,
      "learning_rate": 3.035e-05,
      "loss": 0.001,
      "step": 393
    },
    {
      "epoch": 0.394,
      "grad_norm": 0.6580924391746521,
      "learning_rate": 3.03e-05,
      "loss": 0.0052,
      "step": 394
    },
    {
      "epoch": 0.395,
      "grad_norm": 0.03222625330090523,
      "learning_rate": 3.025e-05,
      "loss": 0.0006,
      "step": 395
    },
    {
      "epoch": 0.396,
      "grad_norm": 0.03777890279889107,
      "learning_rate": 3.02e-05,
      "loss": 0.0005,
      "step": 396
    },
    {
      "epoch": 0.397,
      "grad_norm": 0.5975565314292908,
      "learning_rate": 3.015e-05,
      "loss": 0.0074,
      "step": 397
    },
    {
      "epoch": 0.398,
      "grad_norm": 0.10729031264781952,
      "learning_rate": 3.01e-05,
      "loss": 0.0013,
      "step": 398
    },
    {
      "epoch": 0.399,
      "grad_norm": 0.24098387360572815,
      "learning_rate": 3.0050000000000002e-05,
      "loss": 0.003,
      "step": 399
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.03505631908774376,
      "learning_rate": 3e-05,
      "loss": 0.0004,
      "step": 400
    },
    {
      "epoch": 0.401,
      "grad_norm": 0.07665152102708817,
      "learning_rate": 2.995e-05,
      "loss": 0.0011,
      "step": 401
    },
    {
      "epoch": 0.402,
      "grad_norm": 0.648971438407898,
      "learning_rate": 2.9900000000000002e-05,
      "loss": 0.0063,
      "step": 402
    },
    {
      "epoch": 0.403,
      "grad_norm": 0.026456115767359734,
      "learning_rate": 2.985e-05,
      "loss": 0.0003,
      "step": 403
    },
    {
      "epoch": 0.404,
      "grad_norm": 0.013617908582091331,
      "learning_rate": 2.98e-05,
      "loss": 0.0002,
      "step": 404
    },
    {
      "epoch": 0.405,
      "grad_norm": 0.10085437446832657,
      "learning_rate": 2.975e-05,
      "loss": 0.0007,
      "step": 405
    },
    {
      "epoch": 0.406,
      "grad_norm": 0.05705022066831589,
      "learning_rate": 2.97e-05,
      "loss": 0.001,
      "step": 406
    },
    {
      "epoch": 0.407,
      "grad_norm": 0.02858663722872734,
      "learning_rate": 2.965e-05,
      "loss": 0.0005,
      "step": 407
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.8343358039855957,
      "learning_rate": 2.96e-05,
      "loss": 0.01,
      "step": 408
    },
    {
      "epoch": 0.409,
      "grad_norm": 0.01523924246430397,
      "learning_rate": 2.955e-05,
      "loss": 0.0002,
      "step": 409
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.03412330523133278,
      "learning_rate": 2.95e-05,
      "loss": 0.0009,
      "step": 410
    },
    {
      "epoch": 0.411,
      "grad_norm": 0.033613547682762146,
      "learning_rate": 2.945e-05,
      "loss": 0.0007,
      "step": 411
    },
    {
      "epoch": 0.412,
      "grad_norm": 0.004285340663045645,
      "learning_rate": 2.94e-05,
      "loss": 0.0001,
      "step": 412
    },
    {
      "epoch": 0.413,
      "grad_norm": 0.15071608126163483,
      "learning_rate": 2.935e-05,
      "loss": 0.0018,
      "step": 413
    },
    {
      "epoch": 0.414,
      "grad_norm": 0.029777437448501587,
      "learning_rate": 2.93e-05,
      "loss": 0.0004,
      "step": 414
    },
    {
      "epoch": 0.415,
      "grad_norm": 0.05312579125165939,
      "learning_rate": 2.925e-05,
      "loss": 0.0003,
      "step": 415
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.040747493505477905,
      "learning_rate": 2.9199999999999998e-05,
      "loss": 0.0004,
      "step": 416
    },
    {
      "epoch": 0.417,
      "grad_norm": 0.030509185045957565,
      "learning_rate": 2.915e-05,
      "loss": 0.0005,
      "step": 417
    },
    {
      "epoch": 0.418,
      "grad_norm": 0.09024572372436523,
      "learning_rate": 2.91e-05,
      "loss": 0.0014,
      "step": 418
    },
    {
      "epoch": 0.419,
      "grad_norm": 0.028852706775069237,
      "learning_rate": 2.9049999999999998e-05,
      "loss": 0.0003,
      "step": 419
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.048573482781648636,
      "learning_rate": 2.9e-05,
      "loss": 0.0008,
      "step": 420
    },
    {
      "epoch": 0.421,
      "grad_norm": 0.20896443724632263,
      "learning_rate": 2.895e-05,
      "loss": 0.003,
      "step": 421
    },
    {
      "epoch": 0.422,
      "grad_norm": 0.009394263848662376,
      "learning_rate": 2.8899999999999998e-05,
      "loss": 0.0002,
      "step": 422
    },
    {
      "epoch": 0.423,
      "grad_norm": 0.012107898481190205,
      "learning_rate": 2.885e-05,
      "loss": 0.0003,
      "step": 423
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.9778035879135132,
      "learning_rate": 2.88e-05,
      "loss": 0.0187,
      "step": 424
    },
    {
      "epoch": 0.425,
      "grad_norm": 0.00620895205065608,
      "learning_rate": 2.8749999999999997e-05,
      "loss": 0.0001,
      "step": 425
    },
    {
      "epoch": 0.426,
      "grad_norm": 0.8209475874900818,
      "learning_rate": 2.87e-05,
      "loss": 0.007,
      "step": 426
    },
    {
      "epoch": 0.427,
      "grad_norm": 5.543642997741699,
      "learning_rate": 2.865e-05,
      "loss": 0.0677,
      "step": 427
    },
    {
      "epoch": 0.428,
      "grad_norm": 0.1187695860862732,
      "learning_rate": 2.86e-05,
      "loss": 0.0018,
      "step": 428
    },
    {
      "epoch": 0.429,
      "grad_norm": 4.282652378082275,
      "learning_rate": 2.855e-05,
      "loss": 0.006,
      "step": 429
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.012835909612476826,
      "learning_rate": 2.8499999999999998e-05,
      "loss": 0.0002,
      "step": 430
    },
    {
      "epoch": 0.431,
      "grad_norm": 0.04681053012609482,
      "learning_rate": 2.845e-05,
      "loss": 0.0009,
      "step": 431
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.09793543815612793,
      "learning_rate": 2.84e-05,
      "loss": 0.0012,
      "step": 432
    },
    {
      "epoch": 0.433,
      "grad_norm": 0.09480258822441101,
      "learning_rate": 2.8349999999999998e-05,
      "loss": 0.0016,
      "step": 433
    },
    {
      "epoch": 0.434,
      "grad_norm": 0.008208028972148895,
      "learning_rate": 2.83e-05,
      "loss": 0.0002,
      "step": 434
    },
    {
      "epoch": 0.435,
      "grad_norm": 0.010687584988772869,
      "learning_rate": 2.825e-05,
      "loss": 0.0002,
      "step": 435
    },
    {
      "epoch": 0.436,
      "grad_norm": 0.005844020284712315,
      "learning_rate": 2.8199999999999998e-05,
      "loss": 0.0001,
      "step": 436
    },
    {
      "epoch": 0.437,
      "grad_norm": 0.007917888462543488,
      "learning_rate": 2.815e-05,
      "loss": 0.0001,
      "step": 437
    },
    {
      "epoch": 0.438,
      "grad_norm": 0.024676967412233353,
      "learning_rate": 2.8100000000000005e-05,
      "loss": 0.0003,
      "step": 438
    },
    {
      "epoch": 0.439,
      "grad_norm": 0.1766294687986374,
      "learning_rate": 2.8050000000000004e-05,
      "loss": 0.0024,
      "step": 439
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.12052401155233383,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 0.0025,
      "step": 440
    },
    {
      "epoch": 0.441,
      "grad_norm": 0.009472265839576721,
      "learning_rate": 2.7950000000000005e-05,
      "loss": 0.0001,
      "step": 441
    },
    {
      "epoch": 0.442,
      "grad_norm": 0.04719381034374237,
      "learning_rate": 2.7900000000000004e-05,
      "loss": 0.0011,
      "step": 442
    },
    {
      "epoch": 0.443,
      "grad_norm": 0.15909545123577118,
      "learning_rate": 2.7850000000000003e-05,
      "loss": 0.0036,
      "step": 443
    },
    {
      "epoch": 0.444,
      "grad_norm": 0.003987517207860947,
      "learning_rate": 2.7800000000000005e-05,
      "loss": 0.0001,
      "step": 444
    },
    {
      "epoch": 0.445,
      "grad_norm": 0.6310037970542908,
      "learning_rate": 2.7750000000000004e-05,
      "loss": 0.003,
      "step": 445
    },
    {
      "epoch": 0.446,
      "grad_norm": 0.009749664925038815,
      "learning_rate": 2.7700000000000002e-05,
      "loss": 0.0002,
      "step": 446
    },
    {
      "epoch": 0.447,
      "grad_norm": 0.06915727257728577,
      "learning_rate": 2.7650000000000005e-05,
      "loss": 0.001,
      "step": 447
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.10073921084403992,
      "learning_rate": 2.7600000000000003e-05,
      "loss": 0.0009,
      "step": 448
    },
    {
      "epoch": 0.449,
      "grad_norm": 0.034063730388879776,
      "learning_rate": 2.7550000000000002e-05,
      "loss": 0.0005,
      "step": 449
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.08798513561487198,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 0.001,
      "step": 450
    },
    {
      "epoch": 0.451,
      "grad_norm": 0.056027211248874664,
      "learning_rate": 2.7450000000000003e-05,
      "loss": 0.0006,
      "step": 451
    },
    {
      "epoch": 0.452,
      "grad_norm": 0.015797464177012444,
      "learning_rate": 2.7400000000000002e-05,
      "loss": 0.0003,
      "step": 452
    },
    {
      "epoch": 0.453,
      "grad_norm": 0.08833306282758713,
      "learning_rate": 2.7350000000000004e-05,
      "loss": 0.001,
      "step": 453
    },
    {
      "epoch": 0.454,
      "grad_norm": 0.004505465738475323,
      "learning_rate": 2.7300000000000003e-05,
      "loss": 0.0001,
      "step": 454
    },
    {
      "epoch": 0.455,
      "grad_norm": 0.020944107323884964,
      "learning_rate": 2.725e-05,
      "loss": 0.0003,
      "step": 455
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.588302493095398,
      "learning_rate": 2.7200000000000004e-05,
      "loss": 0.0035,
      "step": 456
    },
    {
      "epoch": 0.457,
      "grad_norm": 0.08111146092414856,
      "learning_rate": 2.7150000000000003e-05,
      "loss": 0.0012,
      "step": 457
    },
    {
      "epoch": 0.458,
      "grad_norm": 0.029514005407691002,
      "learning_rate": 2.7100000000000005e-05,
      "loss": 0.0003,
      "step": 458
    },
    {
      "epoch": 0.459,
      "grad_norm": 0.13771359622478485,
      "learning_rate": 2.7050000000000004e-05,
      "loss": 0.0024,
      "step": 459
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.019381657242774963,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.0002,
      "step": 460
    },
    {
      "epoch": 0.461,
      "grad_norm": 0.011146440170705318,
      "learning_rate": 2.6950000000000005e-05,
      "loss": 0.0001,
      "step": 461
    },
    {
      "epoch": 0.462,
      "grad_norm": 0.004499862901866436,
      "learning_rate": 2.6900000000000003e-05,
      "loss": 0.0001,
      "step": 462
    },
    {
      "epoch": 0.463,
      "grad_norm": 0.02180766686797142,
      "learning_rate": 2.6850000000000002e-05,
      "loss": 0.0003,
      "step": 463
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.011750372126698494,
      "learning_rate": 2.6800000000000004e-05,
      "loss": 0.0002,
      "step": 464
    },
    {
      "epoch": 0.465,
      "grad_norm": 0.007946131750941277,
      "learning_rate": 2.6750000000000003e-05,
      "loss": 0.0001,
      "step": 465
    },
    {
      "epoch": 0.466,
      "grad_norm": 0.029550733044743538,
      "learning_rate": 2.6700000000000002e-05,
      "loss": 0.0005,
      "step": 466
    },
    {
      "epoch": 0.467,
      "grad_norm": 0.02530788816511631,
      "learning_rate": 2.6650000000000004e-05,
      "loss": 0.0007,
      "step": 467
    },
    {
      "epoch": 0.468,
      "grad_norm": 0.017881721258163452,
      "learning_rate": 2.6600000000000003e-05,
      "loss": 0.0003,
      "step": 468
    },
    {
      "epoch": 0.469,
      "grad_norm": 0.004417032469063997,
      "learning_rate": 2.655e-05,
      "loss": 0.0001,
      "step": 469
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.0034640992525964975,
      "learning_rate": 2.6500000000000004e-05,
      "loss": 0.0,
      "step": 470
    },
    {
      "epoch": 0.471,
      "grad_norm": 0.4271959960460663,
      "learning_rate": 2.6450000000000003e-05,
      "loss": 0.0046,
      "step": 471
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.003760604653507471,
      "learning_rate": 2.64e-05,
      "loss": 0.0001,
      "step": 472
    },
    {
      "epoch": 0.473,
      "grad_norm": 0.027142424136400223,
      "learning_rate": 2.6350000000000004e-05,
      "loss": 0.0004,
      "step": 473
    },
    {
      "epoch": 0.474,
      "grad_norm": 0.008068841882050037,
      "learning_rate": 2.6300000000000002e-05,
      "loss": 0.0001,
      "step": 474
    },
    {
      "epoch": 0.475,
      "grad_norm": 0.07065203785896301,
      "learning_rate": 2.625e-05,
      "loss": 0.0013,
      "step": 475
    },
    {
      "epoch": 0.476,
      "grad_norm": 0.02702869288623333,
      "learning_rate": 2.6200000000000003e-05,
      "loss": 0.0005,
      "step": 476
    },
    {
      "epoch": 0.477,
      "grad_norm": 0.10572324693202972,
      "learning_rate": 2.6150000000000002e-05,
      "loss": 0.0015,
      "step": 477
    },
    {
      "epoch": 0.478,
      "grad_norm": 0.16173431277275085,
      "learning_rate": 2.61e-05,
      "loss": 0.0026,
      "step": 478
    },
    {
      "epoch": 0.479,
      "grad_norm": 0.04907829314470291,
      "learning_rate": 2.6050000000000003e-05,
      "loss": 0.0007,
      "step": 479
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.20344479382038116,
      "learning_rate": 2.6000000000000002e-05,
      "loss": 0.0015,
      "step": 480
    },
    {
      "epoch": 0.481,
      "grad_norm": 0.42665350437164307,
      "learning_rate": 2.595e-05,
      "loss": 0.0047,
      "step": 481
    },
    {
      "epoch": 0.482,
      "grad_norm": 0.0535813644528389,
      "learning_rate": 2.5900000000000003e-05,
      "loss": 0.0009,
      "step": 482
    },
    {
      "epoch": 0.483,
      "grad_norm": 0.0036065480671823025,
      "learning_rate": 2.585e-05,
      "loss": 0.0001,
      "step": 483
    },
    {
      "epoch": 0.484,
      "grad_norm": 0.6225600838661194,
      "learning_rate": 2.58e-05,
      "loss": 0.0092,
      "step": 484
    },
    {
      "epoch": 0.485,
      "grad_norm": 0.011610513553023338,
      "learning_rate": 2.5750000000000002e-05,
      "loss": 0.0001,
      "step": 485
    },
    {
      "epoch": 0.486,
      "grad_norm": 0.0022764592431485653,
      "learning_rate": 2.57e-05,
      "loss": 0.0001,
      "step": 486
    },
    {
      "epoch": 0.487,
      "grad_norm": 0.004494371358305216,
      "learning_rate": 2.5650000000000003e-05,
      "loss": 0.0001,
      "step": 487
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.01763739623129368,
      "learning_rate": 2.5600000000000002e-05,
      "loss": 0.0003,
      "step": 488
    },
    {
      "epoch": 0.489,
      "grad_norm": 0.024503076449036598,
      "learning_rate": 2.555e-05,
      "loss": 0.0004,
      "step": 489
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.2063368558883667,
      "learning_rate": 2.5500000000000003e-05,
      "loss": 0.0117,
      "step": 490
    },
    {
      "epoch": 0.491,
      "grad_norm": 0.1648157685995102,
      "learning_rate": 2.5450000000000002e-05,
      "loss": 0.0047,
      "step": 491
    },
    {
      "epoch": 0.492,
      "grad_norm": 0.0012365110451355577,
      "learning_rate": 2.54e-05,
      "loss": 0.0,
      "step": 492
    },
    {
      "epoch": 0.493,
      "grad_norm": 0.04882184416055679,
      "learning_rate": 2.5350000000000003e-05,
      "loss": 0.0005,
      "step": 493
    },
    {
      "epoch": 0.494,
      "grad_norm": 0.002729390049353242,
      "learning_rate": 2.5300000000000002e-05,
      "loss": 0.0001,
      "step": 494
    },
    {
      "epoch": 0.495,
      "grad_norm": 0.018219230696558952,
      "learning_rate": 2.525e-05,
      "loss": 0.0003,
      "step": 495
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.3249334990978241,
      "learning_rate": 2.5200000000000003e-05,
      "loss": 0.0021,
      "step": 496
    },
    {
      "epoch": 0.497,
      "grad_norm": 0.013823691755533218,
      "learning_rate": 2.515e-05,
      "loss": 0.0002,
      "step": 497
    },
    {
      "epoch": 0.498,
      "grad_norm": 0.01051646564155817,
      "learning_rate": 2.51e-05,
      "loss": 0.0002,
      "step": 498
    },
    {
      "epoch": 0.499,
      "grad_norm": 0.31208109855651855,
      "learning_rate": 2.5050000000000002e-05,
      "loss": 0.001,
      "step": 499
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.7074214220046997,
      "learning_rate": 2.5e-05,
      "loss": 0.0095,
      "step": 500
    },
    {
      "epoch": 0.501,
      "grad_norm": 0.006797709967941046,
      "learning_rate": 2.495e-05,
      "loss": 0.0001,
      "step": 501
    },
    {
      "epoch": 0.502,
      "grad_norm": 2.7100298404693604,
      "learning_rate": 2.4900000000000002e-05,
      "loss": 0.0223,
      "step": 502
    },
    {
      "epoch": 0.503,
      "grad_norm": 0.21239709854125977,
      "learning_rate": 2.485e-05,
      "loss": 0.0033,
      "step": 503
    },
    {
      "epoch": 0.504,
      "grad_norm": 16.949417114257812,
      "learning_rate": 2.48e-05,
      "loss": 0.097,
      "step": 504
    },
    {
      "epoch": 0.505,
      "grad_norm": 0.018490703776478767,
      "learning_rate": 2.4750000000000002e-05,
      "loss": 0.0003,
      "step": 505
    },
    {
      "epoch": 0.506,
      "grad_norm": 0.05803884193301201,
      "learning_rate": 2.47e-05,
      "loss": 0.0005,
      "step": 506
    },
    {
      "epoch": 0.507,
      "grad_norm": 0.41117262840270996,
      "learning_rate": 2.465e-05,
      "loss": 0.0043,
      "step": 507
    },
    {
      "epoch": 0.508,
      "grad_norm": 0.1032649502158165,
      "learning_rate": 2.46e-05,
      "loss": 0.0015,
      "step": 508
    },
    {
      "epoch": 0.509,
      "grad_norm": 0.014919322915375233,
      "learning_rate": 2.455e-05,
      "loss": 0.0002,
      "step": 509
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.023674409836530685,
      "learning_rate": 2.45e-05,
      "loss": 0.0004,
      "step": 510
    },
    {
      "epoch": 0.511,
      "grad_norm": 0.8426061272621155,
      "learning_rate": 2.445e-05,
      "loss": 0.0075,
      "step": 511
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.10260830074548721,
      "learning_rate": 2.44e-05,
      "loss": 0.0014,
      "step": 512
    },
    {
      "epoch": 0.513,
      "grad_norm": 0.07971969246864319,
      "learning_rate": 2.435e-05,
      "loss": 0.001,
      "step": 513
    },
    {
      "epoch": 0.514,
      "grad_norm": 0.02081056497991085,
      "learning_rate": 2.43e-05,
      "loss": 0.0002,
      "step": 514
    },
    {
      "epoch": 0.515,
      "grad_norm": 0.03137494623661041,
      "learning_rate": 2.425e-05,
      "loss": 0.0004,
      "step": 515
    },
    {
      "epoch": 0.516,
      "grad_norm": 0.005836919881403446,
      "learning_rate": 2.4200000000000002e-05,
      "loss": 0.0001,
      "step": 516
    },
    {
      "epoch": 0.517,
      "grad_norm": 0.036181870847940445,
      "learning_rate": 2.415e-05,
      "loss": 0.0003,
      "step": 517
    },
    {
      "epoch": 0.518,
      "grad_norm": 0.013778023421764374,
      "learning_rate": 2.41e-05,
      "loss": 0.0003,
      "step": 518
    },
    {
      "epoch": 0.519,
      "grad_norm": 0.020412633195519447,
      "learning_rate": 2.4050000000000002e-05,
      "loss": 0.0004,
      "step": 519
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.767603874206543,
      "learning_rate": 2.4e-05,
      "loss": 0.0138,
      "step": 520
    },
    {
      "epoch": 0.521,
      "grad_norm": 0.016706742346286774,
      "learning_rate": 2.395e-05,
      "loss": 0.0003,
      "step": 521
    },
    {
      "epoch": 0.522,
      "grad_norm": 0.01245132740586996,
      "learning_rate": 2.39e-05,
      "loss": 0.0002,
      "step": 522
    },
    {
      "epoch": 0.523,
      "grad_norm": 0.03057226538658142,
      "learning_rate": 2.385e-05,
      "loss": 0.0004,
      "step": 523
    },
    {
      "epoch": 0.524,
      "grad_norm": 0.033794011920690536,
      "learning_rate": 2.38e-05,
      "loss": 0.0005,
      "step": 524
    },
    {
      "epoch": 0.525,
      "grad_norm": 0.008373543620109558,
      "learning_rate": 2.375e-05,
      "loss": 0.0001,
      "step": 525
    },
    {
      "epoch": 0.526,
      "grad_norm": 3.7036492824554443,
      "learning_rate": 2.37e-05,
      "loss": 0.0569,
      "step": 526
    },
    {
      "epoch": 0.527,
      "grad_norm": 0.002721528522670269,
      "learning_rate": 2.365e-05,
      "loss": 0.0,
      "step": 527
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.011447464115917683,
      "learning_rate": 2.36e-05,
      "loss": 0.0002,
      "step": 528
    },
    {
      "epoch": 0.529,
      "grad_norm": 0.030470823869109154,
      "learning_rate": 2.355e-05,
      "loss": 0.0006,
      "step": 529
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.005107922479510307,
      "learning_rate": 2.35e-05,
      "loss": 0.0001,
      "step": 530
    },
    {
      "epoch": 0.531,
      "grad_norm": 0.39950376749038696,
      "learning_rate": 2.345e-05,
      "loss": 0.0074,
      "step": 531
    },
    {
      "epoch": 0.532,
      "grad_norm": 0.01241280511021614,
      "learning_rate": 2.3400000000000003e-05,
      "loss": 0.0002,
      "step": 532
    },
    {
      "epoch": 0.533,
      "grad_norm": 0.21443650126457214,
      "learning_rate": 2.3350000000000002e-05,
      "loss": 0.0019,
      "step": 533
    },
    {
      "epoch": 0.534,
      "grad_norm": 0.033243995159864426,
      "learning_rate": 2.3300000000000004e-05,
      "loss": 0.0005,
      "step": 534
    },
    {
      "epoch": 0.535,
      "grad_norm": 0.029568729922175407,
      "learning_rate": 2.3250000000000003e-05,
      "loss": 0.0007,
      "step": 535
    },
    {
      "epoch": 0.536,
      "grad_norm": 79.54789733886719,
      "learning_rate": 2.32e-05,
      "loss": 0.2159,
      "step": 536
    },
    {
      "epoch": 0.537,
      "grad_norm": 0.5597098469734192,
      "learning_rate": 2.3150000000000004e-05,
      "loss": 0.0019,
      "step": 537
    },
    {
      "epoch": 0.538,
      "grad_norm": 0.012710729613900185,
      "learning_rate": 2.3100000000000002e-05,
      "loss": 0.0002,
      "step": 538
    },
    {
      "epoch": 0.539,
      "grad_norm": 0.037064094096422195,
      "learning_rate": 2.305e-05,
      "loss": 0.0004,
      "step": 539
    },
    {
      "epoch": 0.54,
      "grad_norm": 95.16487121582031,
      "learning_rate": 2.3000000000000003e-05,
      "loss": 0.4118,
      "step": 540
    },
    {
      "epoch": 0.541,
      "grad_norm": 0.33467236161231995,
      "learning_rate": 2.2950000000000002e-05,
      "loss": 0.0029,
      "step": 541
    },
    {
      "epoch": 0.542,
      "grad_norm": 0.06634562462568283,
      "learning_rate": 2.29e-05,
      "loss": 0.0008,
      "step": 542
    },
    {
      "epoch": 0.543,
      "grad_norm": 0.001816000323742628,
      "learning_rate": 2.2850000000000003e-05,
      "loss": 0.0,
      "step": 543
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.17960280179977417,
      "learning_rate": 2.2800000000000002e-05,
      "loss": 0.0016,
      "step": 544
    },
    {
      "epoch": 0.545,
      "grad_norm": 0.008186801336705685,
      "learning_rate": 2.275e-05,
      "loss": 0.0001,
      "step": 545
    },
    {
      "epoch": 0.546,
      "grad_norm": 0.8070276975631714,
      "learning_rate": 2.2700000000000003e-05,
      "loss": 0.012,
      "step": 546
    },
    {
      "epoch": 0.547,
      "grad_norm": 0.06153208389878273,
      "learning_rate": 2.265e-05,
      "loss": 0.0009,
      "step": 547
    },
    {
      "epoch": 0.548,
      "grad_norm": 0.07535489648580551,
      "learning_rate": 2.26e-05,
      "loss": 0.0014,
      "step": 548
    },
    {
      "epoch": 0.549,
      "grad_norm": 0.04790527746081352,
      "learning_rate": 2.2550000000000003e-05,
      "loss": 0.0006,
      "step": 549
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.06470261514186859,
      "learning_rate": 2.25e-05,
      "loss": 0.0013,
      "step": 550
    },
    {
      "epoch": 0.551,
      "grad_norm": 0.019929416477680206,
      "learning_rate": 2.245e-05,
      "loss": 0.0003,
      "step": 551
    },
    {
      "epoch": 0.552,
      "grad_norm": 1.5800739526748657,
      "learning_rate": 2.2400000000000002e-05,
      "loss": 0.0222,
      "step": 552
    },
    {
      "epoch": 0.553,
      "grad_norm": 0.005612990353256464,
      "learning_rate": 2.235e-05,
      "loss": 0.0001,
      "step": 553
    },
    {
      "epoch": 0.554,
      "grad_norm": 0.07407942414283752,
      "learning_rate": 2.23e-05,
      "loss": 0.0008,
      "step": 554
    },
    {
      "epoch": 0.555,
      "grad_norm": 0.7891718149185181,
      "learning_rate": 2.2250000000000002e-05,
      "loss": 0.0016,
      "step": 555
    },
    {
      "epoch": 0.556,
      "grad_norm": 0.05607275664806366,
      "learning_rate": 2.22e-05,
      "loss": 0.0006,
      "step": 556
    },
    {
      "epoch": 0.557,
      "grad_norm": 1.1944379806518555,
      "learning_rate": 2.215e-05,
      "loss": 0.0104,
      "step": 557
    },
    {
      "epoch": 0.558,
      "grad_norm": 0.015098655596375465,
      "learning_rate": 2.2100000000000002e-05,
      "loss": 0.0002,
      "step": 558
    },
    {
      "epoch": 0.559,
      "grad_norm": 0.07234181463718414,
      "learning_rate": 2.205e-05,
      "loss": 0.0005,
      "step": 559
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.10661467164754868,
      "learning_rate": 2.2000000000000003e-05,
      "loss": 0.001,
      "step": 560
    },
    {
      "epoch": 0.561,
      "grad_norm": 0.06889642030000687,
      "learning_rate": 2.195e-05,
      "loss": 0.0009,
      "step": 561
    },
    {
      "epoch": 0.562,
      "grad_norm": 0.03725273162126541,
      "learning_rate": 2.19e-05,
      "loss": 0.0004,
      "step": 562
    },
    {
      "epoch": 0.563,
      "grad_norm": 0.0021722784731537104,
      "learning_rate": 2.1850000000000003e-05,
      "loss": 0.0,
      "step": 563
    },
    {
      "epoch": 0.564,
      "grad_norm": 0.005383920390158892,
      "learning_rate": 2.18e-05,
      "loss": 0.0001,
      "step": 564
    },
    {
      "epoch": 0.565,
      "grad_norm": 0.018818557262420654,
      "learning_rate": 2.175e-05,
      "loss": 0.0002,
      "step": 565
    },
    {
      "epoch": 0.566,
      "grad_norm": 0.4208620488643646,
      "learning_rate": 2.1700000000000002e-05,
      "loss": 0.0057,
      "step": 566
    },
    {
      "epoch": 0.567,
      "grad_norm": 0.00665198964998126,
      "learning_rate": 2.165e-05,
      "loss": 0.0001,
      "step": 567
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.2400325983762741,
      "learning_rate": 2.16e-05,
      "loss": 0.0025,
      "step": 568
    },
    {
      "epoch": 0.569,
      "grad_norm": 1.51984441280365,
      "learning_rate": 2.1550000000000002e-05,
      "loss": 0.0118,
      "step": 569
    },
    {
      "epoch": 0.57,
      "grad_norm": 0.06408229470252991,
      "learning_rate": 2.15e-05,
      "loss": 0.0003,
      "step": 570
    },
    {
      "epoch": 0.571,
      "grad_norm": 0.01745736040174961,
      "learning_rate": 2.145e-05,
      "loss": 0.0003,
      "step": 571
    },
    {
      "epoch": 0.572,
      "grad_norm": 0.027806121855974197,
      "learning_rate": 2.1400000000000002e-05,
      "loss": 0.0004,
      "step": 572
    },
    {
      "epoch": 0.573,
      "grad_norm": 0.02911445125937462,
      "learning_rate": 2.135e-05,
      "loss": 0.0003,
      "step": 573
    },
    {
      "epoch": 0.574,
      "grad_norm": 0.05664429813623428,
      "learning_rate": 2.13e-05,
      "loss": 0.0005,
      "step": 574
    },
    {
      "epoch": 0.575,
      "grad_norm": 0.023567672818899155,
      "learning_rate": 2.125e-05,
      "loss": 0.0003,
      "step": 575
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.0076983594335615635,
      "learning_rate": 2.12e-05,
      "loss": 0.0002,
      "step": 576
    },
    {
      "epoch": 0.577,
      "grad_norm": 0.023777537047863007,
      "learning_rate": 2.115e-05,
      "loss": 0.0004,
      "step": 577
    },
    {
      "epoch": 0.578,
      "grad_norm": 0.028359098359942436,
      "learning_rate": 2.11e-05,
      "loss": 0.0003,
      "step": 578
    },
    {
      "epoch": 0.579,
      "grad_norm": 0.022704780101776123,
      "learning_rate": 2.105e-05,
      "loss": 0.0003,
      "step": 579
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.513247013092041,
      "learning_rate": 2.1e-05,
      "loss": 0.0036,
      "step": 580
    },
    {
      "epoch": 0.581,
      "grad_norm": 0.005388072691857815,
      "learning_rate": 2.095e-05,
      "loss": 0.0001,
      "step": 581
    },
    {
      "epoch": 0.582,
      "grad_norm": 0.019947474822402,
      "learning_rate": 2.09e-05,
      "loss": 0.0003,
      "step": 582
    },
    {
      "epoch": 0.583,
      "grad_norm": 0.0131840780377388,
      "learning_rate": 2.085e-05,
      "loss": 0.0002,
      "step": 583
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.26154083013534546,
      "learning_rate": 2.08e-05,
      "loss": 0.001,
      "step": 584
    },
    {
      "epoch": 0.585,
      "grad_norm": 0.0031376774422824383,
      "learning_rate": 2.075e-05,
      "loss": 0.0,
      "step": 585
    },
    {
      "epoch": 0.586,
      "grad_norm": 0.011936264112591743,
      "learning_rate": 2.07e-05,
      "loss": 0.0002,
      "step": 586
    },
    {
      "epoch": 0.587,
      "grad_norm": 0.01370729599148035,
      "learning_rate": 2.065e-05,
      "loss": 0.0002,
      "step": 587
    },
    {
      "epoch": 0.588,
      "grad_norm": 0.027998922392725945,
      "learning_rate": 2.06e-05,
      "loss": 0.0003,
      "step": 588
    },
    {
      "epoch": 0.589,
      "grad_norm": 0.12228266149759293,
      "learning_rate": 2.055e-05,
      "loss": 0.0018,
      "step": 589
    },
    {
      "epoch": 0.59,
      "grad_norm": 0.003393773455172777,
      "learning_rate": 2.05e-05,
      "loss": 0.0001,
      "step": 590
    },
    {
      "epoch": 0.591,
      "grad_norm": 0.10023612529039383,
      "learning_rate": 2.045e-05,
      "loss": 0.0013,
      "step": 591
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.05311816558241844,
      "learning_rate": 2.04e-05,
      "loss": 0.0004,
      "step": 592
    },
    {
      "epoch": 0.593,
      "grad_norm": 0.29434436559677124,
      "learning_rate": 2.035e-05,
      "loss": 0.0045,
      "step": 593
    },
    {
      "epoch": 0.594,
      "grad_norm": 0.13565674424171448,
      "learning_rate": 2.0300000000000002e-05,
      "loss": 0.0015,
      "step": 594
    },
    {
      "epoch": 0.595,
      "grad_norm": 0.015773186460137367,
      "learning_rate": 2.025e-05,
      "loss": 0.0003,
      "step": 595
    },
    {
      "epoch": 0.596,
      "grad_norm": 0.041345156729221344,
      "learning_rate": 2.0200000000000003e-05,
      "loss": 0.0002,
      "step": 596
    },
    {
      "epoch": 0.597,
      "grad_norm": 0.007208212278783321,
      "learning_rate": 2.0150000000000002e-05,
      "loss": 0.0002,
      "step": 597
    },
    {
      "epoch": 0.598,
      "grad_norm": 0.012367544695734978,
      "learning_rate": 2.01e-05,
      "loss": 0.0002,
      "step": 598
    },
    {
      "epoch": 0.599,
      "grad_norm": 4.994925498962402,
      "learning_rate": 2.0050000000000003e-05,
      "loss": 0.0231,
      "step": 599
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.018111461773514748,
      "learning_rate": 2e-05,
      "loss": 0.0002,
      "step": 600
    },
    {
      "epoch": 0.601,
      "grad_norm": 0.028150668367743492,
      "learning_rate": 1.995e-05,
      "loss": 0.0007,
      "step": 601
    },
    {
      "epoch": 0.602,
      "grad_norm": 0.03189831227064133,
      "learning_rate": 1.9900000000000003e-05,
      "loss": 0.0006,
      "step": 602
    },
    {
      "epoch": 0.603,
      "grad_norm": 0.020747676491737366,
      "learning_rate": 1.985e-05,
      "loss": 0.0004,
      "step": 603
    },
    {
      "epoch": 0.604,
      "grad_norm": 0.11436589062213898,
      "learning_rate": 1.9800000000000004e-05,
      "loss": 0.0013,
      "step": 604
    },
    {
      "epoch": 0.605,
      "grad_norm": 0.011351285502314568,
      "learning_rate": 1.9750000000000002e-05,
      "loss": 0.0002,
      "step": 605
    },
    {
      "epoch": 0.606,
      "grad_norm": 0.9545831084251404,
      "learning_rate": 1.97e-05,
      "loss": 0.0005,
      "step": 606
    },
    {
      "epoch": 0.607,
      "grad_norm": 0.10676024109125137,
      "learning_rate": 1.9650000000000003e-05,
      "loss": 0.0015,
      "step": 607
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.007756160106509924,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 0.0001,
      "step": 608
    },
    {
      "epoch": 0.609,
      "grad_norm": 0.01740957796573639,
      "learning_rate": 1.955e-05,
      "loss": 0.0004,
      "step": 609
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.005955579224973917,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 0.0001,
      "step": 610
    },
    {
      "epoch": 0.611,
      "grad_norm": 0.32187461853027344,
      "learning_rate": 1.9450000000000002e-05,
      "loss": 0.0022,
      "step": 611
    },
    {
      "epoch": 0.612,
      "grad_norm": 0.5168185234069824,
      "learning_rate": 1.94e-05,
      "loss": 0.0028,
      "step": 612
    },
    {
      "epoch": 0.613,
      "grad_norm": 0.20620214939117432,
      "learning_rate": 1.9350000000000003e-05,
      "loss": 0.0018,
      "step": 613
    },
    {
      "epoch": 0.614,
      "grad_norm": 0.01433960534632206,
      "learning_rate": 1.93e-05,
      "loss": 0.0003,
      "step": 614
    },
    {
      "epoch": 0.615,
      "grad_norm": 1.1001172065734863,
      "learning_rate": 1.925e-05,
      "loss": 0.0137,
      "step": 615
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.011871173977851868,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.0002,
      "step": 616
    },
    {
      "epoch": 0.617,
      "grad_norm": 0.009317414835095406,
      "learning_rate": 1.915e-05,
      "loss": 0.0001,
      "step": 617
    },
    {
      "epoch": 0.618,
      "grad_norm": 0.009184010326862335,
      "learning_rate": 1.91e-05,
      "loss": 0.0002,
      "step": 618
    },
    {
      "epoch": 0.619,
      "grad_norm": 0.06888782978057861,
      "learning_rate": 1.9050000000000002e-05,
      "loss": 0.0013,
      "step": 619
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.2724575698375702,
      "learning_rate": 1.9e-05,
      "loss": 0.0031,
      "step": 620
    },
    {
      "epoch": 0.621,
      "grad_norm": 5.311041355133057,
      "learning_rate": 1.895e-05,
      "loss": 0.0737,
      "step": 621
    },
    {
      "epoch": 0.622,
      "grad_norm": 0.0023513955529779196,
      "learning_rate": 1.8900000000000002e-05,
      "loss": 0.0,
      "step": 622
    },
    {
      "epoch": 0.623,
      "grad_norm": 0.036267805844545364,
      "learning_rate": 1.885e-05,
      "loss": 0.0007,
      "step": 623
    },
    {
      "epoch": 0.624,
      "grad_norm": 11.933008193969727,
      "learning_rate": 1.88e-05,
      "loss": 0.0143,
      "step": 624
    },
    {
      "epoch": 0.625,
      "grad_norm": 0.08373355120420456,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 0.0013,
      "step": 625
    },
    {
      "epoch": 0.626,
      "grad_norm": 0.028156965970993042,
      "learning_rate": 1.87e-05,
      "loss": 0.0003,
      "step": 626
    },
    {
      "epoch": 0.627,
      "grad_norm": 0.03413109481334686,
      "learning_rate": 1.865e-05,
      "loss": 0.0004,
      "step": 627
    },
    {
      "epoch": 0.628,
      "grad_norm": 0.007449866738170385,
      "learning_rate": 1.86e-05,
      "loss": 0.0001,
      "step": 628
    },
    {
      "epoch": 0.629,
      "grad_norm": 0.023181326687335968,
      "learning_rate": 1.855e-05,
      "loss": 0.0005,
      "step": 629
    },
    {
      "epoch": 0.63,
      "grad_norm": 0.0068915728479623795,
      "learning_rate": 1.85e-05,
      "loss": 0.0001,
      "step": 630
    },
    {
      "epoch": 0.631,
      "grad_norm": 0.011524354107677937,
      "learning_rate": 1.845e-05,
      "loss": 0.0003,
      "step": 631
    },
    {
      "epoch": 0.632,
      "grad_norm": 1.432856798171997,
      "learning_rate": 1.84e-05,
      "loss": 0.0121,
      "step": 632
    },
    {
      "epoch": 0.633,
      "grad_norm": 0.18098583817481995,
      "learning_rate": 1.8350000000000002e-05,
      "loss": 0.0015,
      "step": 633
    },
    {
      "epoch": 0.634,
      "grad_norm": 0.02746022865176201,
      "learning_rate": 1.83e-05,
      "loss": 0.0005,
      "step": 634
    },
    {
      "epoch": 0.635,
      "grad_norm": 0.08125119656324387,
      "learning_rate": 1.825e-05,
      "loss": 0.0012,
      "step": 635
    },
    {
      "epoch": 0.636,
      "grad_norm": 0.2705865502357483,
      "learning_rate": 1.8200000000000002e-05,
      "loss": 0.0024,
      "step": 636
    },
    {
      "epoch": 0.637,
      "grad_norm": 0.01850440539419651,
      "learning_rate": 1.815e-05,
      "loss": 0.0004,
      "step": 637
    },
    {
      "epoch": 0.638,
      "grad_norm": 0.003917642403393984,
      "learning_rate": 1.81e-05,
      "loss": 0.0001,
      "step": 638
    },
    {
      "epoch": 0.639,
      "grad_norm": 0.003634400898590684,
      "learning_rate": 1.805e-05,
      "loss": 0.0001,
      "step": 639
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.06087890639901161,
      "learning_rate": 1.8e-05,
      "loss": 0.0007,
      "step": 640
    },
    {
      "epoch": 0.641,
      "grad_norm": 0.009608910419046879,
      "learning_rate": 1.795e-05,
      "loss": 0.0001,
      "step": 641
    },
    {
      "epoch": 0.642,
      "grad_norm": 0.3715953826904297,
      "learning_rate": 1.79e-05,
      "loss": 0.0029,
      "step": 642
    },
    {
      "epoch": 0.643,
      "grad_norm": 0.002525587100535631,
      "learning_rate": 1.785e-05,
      "loss": 0.0001,
      "step": 643
    },
    {
      "epoch": 0.644,
      "grad_norm": 0.05444797873497009,
      "learning_rate": 1.78e-05,
      "loss": 0.0006,
      "step": 644
    },
    {
      "epoch": 0.645,
      "grad_norm": 0.004893128760159016,
      "learning_rate": 1.775e-05,
      "loss": 0.0001,
      "step": 645
    },
    {
      "epoch": 0.646,
      "grad_norm": 0.013241961598396301,
      "learning_rate": 1.77e-05,
      "loss": 0.0002,
      "step": 646
    },
    {
      "epoch": 0.647,
      "grad_norm": 0.05775521695613861,
      "learning_rate": 1.765e-05,
      "loss": 0.0007,
      "step": 647
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.05108608305454254,
      "learning_rate": 1.76e-05,
      "loss": 0.0008,
      "step": 648
    },
    {
      "epoch": 0.649,
      "grad_norm": 0.08849657326936722,
      "learning_rate": 1.755e-05,
      "loss": 0.001,
      "step": 649
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.15219581127166748,
      "learning_rate": 1.75e-05,
      "loss": 0.0025,
      "step": 650
    },
    {
      "epoch": 0.651,
      "grad_norm": 0.06548521667718887,
      "learning_rate": 1.745e-05,
      "loss": 0.0017,
      "step": 651
    },
    {
      "epoch": 0.652,
      "grad_norm": 0.005498845130205154,
      "learning_rate": 1.74e-05,
      "loss": 0.0001,
      "step": 652
    },
    {
      "epoch": 0.653,
      "grad_norm": 0.003025294281542301,
      "learning_rate": 1.7349999999999998e-05,
      "loss": 0.0,
      "step": 653
    },
    {
      "epoch": 0.654,
      "grad_norm": 0.10778337717056274,
      "learning_rate": 1.73e-05,
      "loss": 0.0014,
      "step": 654
    },
    {
      "epoch": 0.655,
      "grad_norm": 0.17014944553375244,
      "learning_rate": 1.725e-05,
      "loss": 0.0022,
      "step": 655
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.002056881319731474,
      "learning_rate": 1.7199999999999998e-05,
      "loss": 0.0,
      "step": 656
    },
    {
      "epoch": 0.657,
      "grad_norm": 0.07731087505817413,
      "learning_rate": 1.7150000000000004e-05,
      "loss": 0.0012,
      "step": 657
    },
    {
      "epoch": 0.658,
      "grad_norm": 0.0026323040947318077,
      "learning_rate": 1.7100000000000002e-05,
      "loss": 0.0001,
      "step": 658
    },
    {
      "epoch": 0.659,
      "grad_norm": 0.10145913064479828,
      "learning_rate": 1.705e-05,
      "loss": 0.0011,
      "step": 659
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.03358780965209007,
      "learning_rate": 1.7000000000000003e-05,
      "loss": 0.0002,
      "step": 660
    },
    {
      "epoch": 0.661,
      "grad_norm": 0.014449049718677998,
      "learning_rate": 1.6950000000000002e-05,
      "loss": 0.0002,
      "step": 661
    },
    {
      "epoch": 0.662,
      "grad_norm": 0.025396710261702538,
      "learning_rate": 1.69e-05,
      "loss": 0.0003,
      "step": 662
    },
    {
      "epoch": 0.663,
      "grad_norm": 0.22468653321266174,
      "learning_rate": 1.6850000000000003e-05,
      "loss": 0.0009,
      "step": 663
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.006876631174236536,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.0001,
      "step": 664
    },
    {
      "epoch": 0.665,
      "grad_norm": 0.007108351215720177,
      "learning_rate": 1.675e-05,
      "loss": 0.0001,
      "step": 665
    },
    {
      "epoch": 0.666,
      "grad_norm": 0.07144978642463684,
      "learning_rate": 1.6700000000000003e-05,
      "loss": 0.0008,
      "step": 666
    },
    {
      "epoch": 0.667,
      "grad_norm": 0.003581743221729994,
      "learning_rate": 1.665e-05,
      "loss": 0.0001,
      "step": 667
    },
    {
      "epoch": 0.668,
      "grad_norm": 0.0005179699510335922,
      "learning_rate": 1.66e-05,
      "loss": 0.0,
      "step": 668
    },
    {
      "epoch": 0.669,
      "grad_norm": 0.025385582819581032,
      "learning_rate": 1.6550000000000002e-05,
      "loss": 0.0004,
      "step": 669
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.5353188514709473,
      "learning_rate": 1.65e-05,
      "loss": 0.002,
      "step": 670
    },
    {
      "epoch": 0.671,
      "grad_norm": 0.014441017061471939,
      "learning_rate": 1.645e-05,
      "loss": 0.0002,
      "step": 671
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.02649061381816864,
      "learning_rate": 1.6400000000000002e-05,
      "loss": 0.0004,
      "step": 672
    },
    {
      "epoch": 0.673,
      "grad_norm": 0.004581393674015999,
      "learning_rate": 1.635e-05,
      "loss": 0.0001,
      "step": 673
    },
    {
      "epoch": 0.674,
      "grad_norm": 0.005940400995314121,
      "learning_rate": 1.63e-05,
      "loss": 0.0001,
      "step": 674
    },
    {
      "epoch": 0.675,
      "grad_norm": 0.006708902306854725,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 0.0001,
      "step": 675
    },
    {
      "epoch": 0.676,
      "grad_norm": 0.013209186494350433,
      "learning_rate": 1.62e-05,
      "loss": 0.0003,
      "step": 676
    },
    {
      "epoch": 0.677,
      "grad_norm": 0.014630908146500587,
      "learning_rate": 1.6150000000000003e-05,
      "loss": 0.0003,
      "step": 677
    },
    {
      "epoch": 0.678,
      "grad_norm": 0.0046805343590676785,
      "learning_rate": 1.6100000000000002e-05,
      "loss": 0.0001,
      "step": 678
    },
    {
      "epoch": 0.679,
      "grad_norm": 0.00376532762311399,
      "learning_rate": 1.605e-05,
      "loss": 0.0001,
      "step": 679
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.042892877012491226,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.0006,
      "step": 680
    },
    {
      "epoch": 0.681,
      "grad_norm": 0.002426143502816558,
      "learning_rate": 1.595e-05,
      "loss": 0.0001,
      "step": 681
    },
    {
      "epoch": 0.682,
      "grad_norm": 0.06339676678180695,
      "learning_rate": 1.59e-05,
      "loss": 0.0012,
      "step": 682
    },
    {
      "epoch": 0.683,
      "grad_norm": 0.04500456526875496,
      "learning_rate": 1.5850000000000002e-05,
      "loss": 0.0006,
      "step": 683
    },
    {
      "epoch": 0.684,
      "grad_norm": 0.007852083072066307,
      "learning_rate": 1.58e-05,
      "loss": 0.0001,
      "step": 684
    },
    {
      "epoch": 0.685,
      "grad_norm": 0.4774598777294159,
      "learning_rate": 1.575e-05,
      "loss": 0.0001,
      "step": 685
    },
    {
      "epoch": 0.686,
      "grad_norm": 0.2874804735183716,
      "learning_rate": 1.5700000000000002e-05,
      "loss": 0.0061,
      "step": 686
    },
    {
      "epoch": 0.687,
      "grad_norm": 0.008148659020662308,
      "learning_rate": 1.565e-05,
      "loss": 0.0002,
      "step": 687
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.0288636963814497,
      "learning_rate": 1.56e-05,
      "loss": 0.0005,
      "step": 688
    },
    {
      "epoch": 0.689,
      "grad_norm": 0.05409226566553116,
      "learning_rate": 1.5550000000000002e-05,
      "loss": 0.0007,
      "step": 689
    },
    {
      "epoch": 0.69,
      "grad_norm": 0.028493884950876236,
      "learning_rate": 1.55e-05,
      "loss": 0.0002,
      "step": 690
    },
    {
      "epoch": 0.691,
      "grad_norm": 0.012079475447535515,
      "learning_rate": 1.545e-05,
      "loss": 0.0002,
      "step": 691
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.029837394133210182,
      "learning_rate": 1.54e-05,
      "loss": 0.0005,
      "step": 692
    },
    {
      "epoch": 0.693,
      "grad_norm": 0.10552256554365158,
      "learning_rate": 1.535e-05,
      "loss": 0.0023,
      "step": 693
    },
    {
      "epoch": 0.694,
      "grad_norm": 0.016757508739829063,
      "learning_rate": 1.53e-05,
      "loss": 0.0002,
      "step": 694
    },
    {
      "epoch": 0.695,
      "grad_norm": 0.0011064663995057344,
      "learning_rate": 1.525e-05,
      "loss": 0.0,
      "step": 695
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.0068527101539075375,
      "learning_rate": 1.52e-05,
      "loss": 0.0001,
      "step": 696
    },
    {
      "epoch": 0.697,
      "grad_norm": 0.006088992580771446,
      "learning_rate": 1.515e-05,
      "loss": 0.0001,
      "step": 697
    },
    {
      "epoch": 0.698,
      "grad_norm": 0.013306736946105957,
      "learning_rate": 1.51e-05,
      "loss": 0.0003,
      "step": 698
    },
    {
      "epoch": 0.699,
      "grad_norm": 0.006600330118089914,
      "learning_rate": 1.505e-05,
      "loss": 0.0002,
      "step": 699
    },
    {
      "epoch": 0.7,
      "grad_norm": 1.1132277250289917,
      "learning_rate": 1.5e-05,
      "loss": 0.0156,
      "step": 700
    },
    {
      "epoch": 0.701,
      "grad_norm": 0.002743343124166131,
      "learning_rate": 1.4950000000000001e-05,
      "loss": 0.0,
      "step": 701
    },
    {
      "epoch": 0.702,
      "grad_norm": 0.08703270554542542,
      "learning_rate": 1.49e-05,
      "loss": 0.0008,
      "step": 702
    },
    {
      "epoch": 0.703,
      "grad_norm": 0.0019683579448610544,
      "learning_rate": 1.485e-05,
      "loss": 0.0,
      "step": 703
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.020406335592269897,
      "learning_rate": 1.48e-05,
      "loss": 0.0005,
      "step": 704
    },
    {
      "epoch": 0.705,
      "grad_norm": 0.017785605043172836,
      "learning_rate": 1.475e-05,
      "loss": 0.0002,
      "step": 705
    },
    {
      "epoch": 0.706,
      "grad_norm": 0.024847358465194702,
      "learning_rate": 1.47e-05,
      "loss": 0.0004,
      "step": 706
    },
    {
      "epoch": 0.707,
      "grad_norm": 0.008174351416528225,
      "learning_rate": 1.465e-05,
      "loss": 0.0002,
      "step": 707
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.00922679528594017,
      "learning_rate": 1.4599999999999999e-05,
      "loss": 0.0001,
      "step": 708
    },
    {
      "epoch": 0.709,
      "grad_norm": 0.013623963110148907,
      "learning_rate": 1.455e-05,
      "loss": 0.0002,
      "step": 709
    },
    {
      "epoch": 0.71,
      "grad_norm": 0.007043900433927774,
      "learning_rate": 1.45e-05,
      "loss": 0.0001,
      "step": 710
    },
    {
      "epoch": 0.711,
      "grad_norm": 0.010899064131081104,
      "learning_rate": 1.4449999999999999e-05,
      "loss": 0.0002,
      "step": 711
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.07751482725143433,
      "learning_rate": 1.44e-05,
      "loss": 0.001,
      "step": 712
    },
    {
      "epoch": 0.713,
      "grad_norm": 0.15539871156215668,
      "learning_rate": 1.435e-05,
      "loss": 0.0013,
      "step": 713
    },
    {
      "epoch": 0.714,
      "grad_norm": 0.05016558617353439,
      "learning_rate": 1.43e-05,
      "loss": 0.0007,
      "step": 714
    },
    {
      "epoch": 0.715,
      "grad_norm": 0.020515013486146927,
      "learning_rate": 1.4249999999999999e-05,
      "loss": 0.0004,
      "step": 715
    },
    {
      "epoch": 0.716,
      "grad_norm": 0.04782690480351448,
      "learning_rate": 1.42e-05,
      "loss": 0.0002,
      "step": 716
    },
    {
      "epoch": 0.717,
      "grad_norm": 0.006226083729416132,
      "learning_rate": 1.415e-05,
      "loss": 0.0001,
      "step": 717
    },
    {
      "epoch": 0.718,
      "grad_norm": 0.0969969779253006,
      "learning_rate": 1.4099999999999999e-05,
      "loss": 0.0009,
      "step": 718
    },
    {
      "epoch": 0.719,
      "grad_norm": 1.3756495714187622,
      "learning_rate": 1.4050000000000003e-05,
      "loss": 0.0112,
      "step": 719
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.013512409292161465,
      "learning_rate": 1.4000000000000001e-05,
      "loss": 0.0002,
      "step": 720
    },
    {
      "epoch": 0.721,
      "grad_norm": 0.01652749627828598,
      "learning_rate": 1.3950000000000002e-05,
      "loss": 0.0003,
      "step": 721
    },
    {
      "epoch": 0.722,
      "grad_norm": 0.1189950704574585,
      "learning_rate": 1.3900000000000002e-05,
      "loss": 0.0014,
      "step": 722
    },
    {
      "epoch": 0.723,
      "grad_norm": 0.5757229924201965,
      "learning_rate": 1.3850000000000001e-05,
      "loss": 0.0067,
      "step": 723
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.006352327298372984,
      "learning_rate": 1.3800000000000002e-05,
      "loss": 0.0001,
      "step": 724
    },
    {
      "epoch": 0.725,
      "grad_norm": 0.007815096527338028,
      "learning_rate": 1.3750000000000002e-05,
      "loss": 0.0002,
      "step": 725
    },
    {
      "epoch": 0.726,
      "grad_norm": 0.03228845074772835,
      "learning_rate": 1.3700000000000001e-05,
      "loss": 0.0004,
      "step": 726
    },
    {
      "epoch": 0.727,
      "grad_norm": 8.8134183883667,
      "learning_rate": 1.3650000000000001e-05,
      "loss": 0.0715,
      "step": 727
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.06635940819978714,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 0.0005,
      "step": 728
    },
    {
      "epoch": 0.729,
      "grad_norm": 0.48394379019737244,
      "learning_rate": 1.3550000000000002e-05,
      "loss": 0.0018,
      "step": 729
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.00907863862812519,
      "learning_rate": 1.3500000000000001e-05,
      "loss": 0.0002,
      "step": 730
    },
    {
      "epoch": 0.731,
      "grad_norm": 0.03987706080079079,
      "learning_rate": 1.3450000000000002e-05,
      "loss": 0.0004,
      "step": 731
    },
    {
      "epoch": 0.732,
      "grad_norm": 0.044660914689302444,
      "learning_rate": 1.3400000000000002e-05,
      "loss": 0.0002,
      "step": 732
    },
    {
      "epoch": 0.733,
      "grad_norm": 0.0437939390540123,
      "learning_rate": 1.3350000000000001e-05,
      "loss": 0.0007,
      "step": 733
    },
    {
      "epoch": 0.734,
      "grad_norm": 0.006563167087733746,
      "learning_rate": 1.3300000000000001e-05,
      "loss": 0.0001,
      "step": 734
    },
    {
      "epoch": 0.735,
      "grad_norm": 0.11308373510837555,
      "learning_rate": 1.3250000000000002e-05,
      "loss": 0.0005,
      "step": 735
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.012653889134526253,
      "learning_rate": 1.32e-05,
      "loss": 0.0001,
      "step": 736
    },
    {
      "epoch": 0.737,
      "grad_norm": 0.030534500256180763,
      "learning_rate": 1.3150000000000001e-05,
      "loss": 0.0004,
      "step": 737
    },
    {
      "epoch": 0.738,
      "grad_norm": 0.011918382719159126,
      "learning_rate": 1.3100000000000002e-05,
      "loss": 0.0002,
      "step": 738
    },
    {
      "epoch": 0.739,
      "grad_norm": 0.044875141233205795,
      "learning_rate": 1.305e-05,
      "loss": 0.0004,
      "step": 739
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.48225271701812744,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.0033,
      "step": 740
    },
    {
      "epoch": 0.741,
      "grad_norm": 0.02178635448217392,
      "learning_rate": 1.2950000000000001e-05,
      "loss": 0.0004,
      "step": 741
    },
    {
      "epoch": 0.742,
      "grad_norm": 0.0019732234068214893,
      "learning_rate": 1.29e-05,
      "loss": 0.0,
      "step": 742
    },
    {
      "epoch": 0.743,
      "grad_norm": 0.409769743680954,
      "learning_rate": 1.285e-05,
      "loss": 0.0038,
      "step": 743
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.019541874527931213,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.0004,
      "step": 744
    },
    {
      "epoch": 0.745,
      "grad_norm": 0.20105722546577454,
      "learning_rate": 1.2750000000000002e-05,
      "loss": 0.002,
      "step": 745
    },
    {
      "epoch": 0.746,
      "grad_norm": 0.015196427702903748,
      "learning_rate": 1.27e-05,
      "loss": 0.0002,
      "step": 746
    },
    {
      "epoch": 0.747,
      "grad_norm": 0.005891786888241768,
      "learning_rate": 1.2650000000000001e-05,
      "loss": 0.0001,
      "step": 747
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.0018881100695580244,
      "learning_rate": 1.2600000000000001e-05,
      "loss": 0.0,
      "step": 748
    },
    {
      "epoch": 0.749,
      "grad_norm": 0.04835719242691994,
      "learning_rate": 1.255e-05,
      "loss": 0.0007,
      "step": 749
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.017309430986642838,
      "learning_rate": 1.25e-05,
      "loss": 0.0005,
      "step": 750
    },
    {
      "epoch": 0.751,
      "grad_norm": 0.11324907839298248,
      "learning_rate": 1.2450000000000001e-05,
      "loss": 0.0019,
      "step": 751
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.6594679951667786,
      "learning_rate": 1.24e-05,
      "loss": 0.0093,
      "step": 752
    },
    {
      "epoch": 0.753,
      "grad_norm": 0.008876515552401543,
      "learning_rate": 1.235e-05,
      "loss": 0.0002,
      "step": 753
    },
    {
      "epoch": 0.754,
      "grad_norm": 0.035812415182590485,
      "learning_rate": 1.23e-05,
      "loss": 0.0006,
      "step": 754
    },
    {
      "epoch": 0.755,
      "grad_norm": 0.43584156036376953,
      "learning_rate": 1.225e-05,
      "loss": 0.0094,
      "step": 755
    },
    {
      "epoch": 0.756,
      "grad_norm": 0.004572391044348478,
      "learning_rate": 1.22e-05,
      "loss": 0.0001,
      "step": 756
    },
    {
      "epoch": 0.757,
      "grad_norm": 0.08857803791761398,
      "learning_rate": 1.215e-05,
      "loss": 0.0013,
      "step": 757
    },
    {
      "epoch": 0.758,
      "grad_norm": 0.07196443527936935,
      "learning_rate": 1.2100000000000001e-05,
      "loss": 0.0009,
      "step": 758
    },
    {
      "epoch": 0.759,
      "grad_norm": 0.035023484379053116,
      "learning_rate": 1.205e-05,
      "loss": 0.0005,
      "step": 759
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.0034198956564068794,
      "learning_rate": 1.2e-05,
      "loss": 0.0,
      "step": 760
    },
    {
      "epoch": 0.761,
      "grad_norm": 0.003835865296423435,
      "learning_rate": 1.195e-05,
      "loss": 0.0001,
      "step": 761
    },
    {
      "epoch": 0.762,
      "grad_norm": 0.048351388424634933,
      "learning_rate": 1.19e-05,
      "loss": 0.0007,
      "step": 762
    },
    {
      "epoch": 0.763,
      "grad_norm": 0.1858168989419937,
      "learning_rate": 1.185e-05,
      "loss": 0.0018,
      "step": 763
    },
    {
      "epoch": 0.764,
      "grad_norm": 0.01984136924147606,
      "learning_rate": 1.18e-05,
      "loss": 0.0003,
      "step": 764
    },
    {
      "epoch": 0.765,
      "grad_norm": 0.006889560259878635,
      "learning_rate": 1.175e-05,
      "loss": 0.0001,
      "step": 765
    },
    {
      "epoch": 0.766,
      "grad_norm": 0.03090742975473404,
      "learning_rate": 1.1700000000000001e-05,
      "loss": 0.0004,
      "step": 766
    },
    {
      "epoch": 0.767,
      "grad_norm": 0.022080978378653526,
      "learning_rate": 1.1650000000000002e-05,
      "loss": 0.0003,
      "step": 767
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.009913180023431778,
      "learning_rate": 1.16e-05,
      "loss": 0.0002,
      "step": 768
    },
    {
      "epoch": 0.769,
      "grad_norm": 0.007388029247522354,
      "learning_rate": 1.1550000000000001e-05,
      "loss": 0.0002,
      "step": 769
    },
    {
      "epoch": 0.77,
      "grad_norm": 0.06596115976572037,
      "learning_rate": 1.1500000000000002e-05,
      "loss": 0.0013,
      "step": 770
    },
    {
      "epoch": 0.771,
      "grad_norm": 0.00667123356834054,
      "learning_rate": 1.145e-05,
      "loss": 0.0001,
      "step": 771
    },
    {
      "epoch": 0.772,
      "grad_norm": 0.14817342162132263,
      "learning_rate": 1.1400000000000001e-05,
      "loss": 0.0012,
      "step": 772
    },
    {
      "epoch": 0.773,
      "grad_norm": 0.013885963708162308,
      "learning_rate": 1.1350000000000001e-05,
      "loss": 0.0002,
      "step": 773
    },
    {
      "epoch": 0.774,
      "grad_norm": 0.06198025122284889,
      "learning_rate": 1.13e-05,
      "loss": 0.0009,
      "step": 774
    },
    {
      "epoch": 0.775,
      "grad_norm": 0.019464630633592606,
      "learning_rate": 1.125e-05,
      "loss": 0.0004,
      "step": 775
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.00670443894341588,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.0001,
      "step": 776
    },
    {
      "epoch": 0.777,
      "grad_norm": 0.007054133806377649,
      "learning_rate": 1.115e-05,
      "loss": 0.0001,
      "step": 777
    },
    {
      "epoch": 0.778,
      "grad_norm": 0.3946709930896759,
      "learning_rate": 1.11e-05,
      "loss": 0.0015,
      "step": 778
    },
    {
      "epoch": 0.779,
      "grad_norm": 0.0172527227550745,
      "learning_rate": 1.1050000000000001e-05,
      "loss": 0.0002,
      "step": 779
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.012671767733991146,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.0002,
      "step": 780
    },
    {
      "epoch": 0.781,
      "grad_norm": 0.00370794371701777,
      "learning_rate": 1.095e-05,
      "loss": 0.0001,
      "step": 781
    },
    {
      "epoch": 0.782,
      "grad_norm": 0.008544066920876503,
      "learning_rate": 1.09e-05,
      "loss": 0.0001,
      "step": 782
    },
    {
      "epoch": 0.783,
      "grad_norm": 0.02166217751801014,
      "learning_rate": 1.0850000000000001e-05,
      "loss": 0.0004,
      "step": 783
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.0224724430590868,
      "learning_rate": 1.08e-05,
      "loss": 0.0004,
      "step": 784
    },
    {
      "epoch": 0.785,
      "grad_norm": 0.3990797698497772,
      "learning_rate": 1.075e-05,
      "loss": 0.0049,
      "step": 785
    },
    {
      "epoch": 0.786,
      "grad_norm": 0.0332941859960556,
      "learning_rate": 1.0700000000000001e-05,
      "loss": 0.0005,
      "step": 786
    },
    {
      "epoch": 0.787,
      "grad_norm": 0.03642550855875015,
      "learning_rate": 1.065e-05,
      "loss": 0.0008,
      "step": 787
    },
    {
      "epoch": 0.788,
      "grad_norm": 0.0030264919623732567,
      "learning_rate": 1.06e-05,
      "loss": 0.0001,
      "step": 788
    },
    {
      "epoch": 0.789,
      "grad_norm": 0.2695549726486206,
      "learning_rate": 1.055e-05,
      "loss": 0.0042,
      "step": 789
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.22749076783657074,
      "learning_rate": 1.05e-05,
      "loss": 0.0029,
      "step": 790
    },
    {
      "epoch": 0.791,
      "grad_norm": 0.004168874584138393,
      "learning_rate": 1.045e-05,
      "loss": 0.0001,
      "step": 791
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.06437068432569504,
      "learning_rate": 1.04e-05,
      "loss": 0.0012,
      "step": 792
    },
    {
      "epoch": 0.793,
      "grad_norm": 0.004262558184564114,
      "learning_rate": 1.035e-05,
      "loss": 0.0001,
      "step": 793
    },
    {
      "epoch": 0.794,
      "grad_norm": 0.01713726297020912,
      "learning_rate": 1.03e-05,
      "loss": 0.0003,
      "step": 794
    },
    {
      "epoch": 0.795,
      "grad_norm": 0.3916183412075043,
      "learning_rate": 1.025e-05,
      "loss": 0.0051,
      "step": 795
    },
    {
      "epoch": 0.796,
      "grad_norm": 0.015425783582031727,
      "learning_rate": 1.02e-05,
      "loss": 0.0003,
      "step": 796
    },
    {
      "epoch": 0.797,
      "grad_norm": 0.0015690712025389075,
      "learning_rate": 1.0150000000000001e-05,
      "loss": 0.0,
      "step": 797
    },
    {
      "epoch": 0.798,
      "grad_norm": 0.01898449845612049,
      "learning_rate": 1.0100000000000002e-05,
      "loss": 0.0002,
      "step": 798
    },
    {
      "epoch": 0.799,
      "grad_norm": 0.002363023813813925,
      "learning_rate": 1.005e-05,
      "loss": 0.0,
      "step": 799
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3801845610141754,
      "learning_rate": 1e-05,
      "loss": 0.0046,
      "step": 800
    },
    {
      "epoch": 0.801,
      "grad_norm": 0.0169058945029974,
      "learning_rate": 9.950000000000001e-06,
      "loss": 0.0003,
      "step": 801
    },
    {
      "epoch": 0.802,
      "grad_norm": 0.03150230646133423,
      "learning_rate": 9.900000000000002e-06,
      "loss": 0.0005,
      "step": 802
    },
    {
      "epoch": 0.803,
      "grad_norm": 0.06719403713941574,
      "learning_rate": 9.85e-06,
      "loss": 0.0008,
      "step": 803
    },
    {
      "epoch": 0.804,
      "grad_norm": 0.01672220043838024,
      "learning_rate": 9.800000000000001e-06,
      "loss": 0.0002,
      "step": 804
    },
    {
      "epoch": 0.805,
      "grad_norm": 0.009610380977392197,
      "learning_rate": 9.750000000000002e-06,
      "loss": 0.0002,
      "step": 805
    },
    {
      "epoch": 0.806,
      "grad_norm": 0.00698771933093667,
      "learning_rate": 9.7e-06,
      "loss": 0.0001,
      "step": 806
    },
    {
      "epoch": 0.807,
      "grad_norm": 0.019222872331738472,
      "learning_rate": 9.65e-06,
      "loss": 0.0003,
      "step": 807
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.007116781547665596,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.0001,
      "step": 808
    },
    {
      "epoch": 0.809,
      "grad_norm": 0.007088342681527138,
      "learning_rate": 9.55e-06,
      "loss": 0.0001,
      "step": 809
    },
    {
      "epoch": 0.81,
      "grad_norm": 0.08785649389028549,
      "learning_rate": 9.5e-06,
      "loss": 0.0005,
      "step": 810
    },
    {
      "epoch": 0.811,
      "grad_norm": 0.11619625240564346,
      "learning_rate": 9.450000000000001e-06,
      "loss": 0.0016,
      "step": 811
    },
    {
      "epoch": 0.812,
      "grad_norm": 0.005009542219340801,
      "learning_rate": 9.4e-06,
      "loss": 0.0001,
      "step": 812
    },
    {
      "epoch": 0.813,
      "grad_norm": 0.01957925595343113,
      "learning_rate": 9.35e-06,
      "loss": 0.0003,
      "step": 813
    },
    {
      "epoch": 0.814,
      "grad_norm": 0.08744234591722488,
      "learning_rate": 9.3e-06,
      "loss": 0.0016,
      "step": 814
    },
    {
      "epoch": 0.815,
      "grad_norm": 0.015920739620923996,
      "learning_rate": 9.25e-06,
      "loss": 0.0004,
      "step": 815
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.12013315409421921,
      "learning_rate": 9.2e-06,
      "loss": 0.0011,
      "step": 816
    },
    {
      "epoch": 0.817,
      "grad_norm": 0.013292346149682999,
      "learning_rate": 9.15e-06,
      "loss": 0.0003,
      "step": 817
    },
    {
      "epoch": 0.818,
      "grad_norm": 0.013593376614153385,
      "learning_rate": 9.100000000000001e-06,
      "loss": 0.0002,
      "step": 818
    },
    {
      "epoch": 0.819,
      "grad_norm": 0.06480636447668076,
      "learning_rate": 9.05e-06,
      "loss": 0.0006,
      "step": 819
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.0008892770856618881,
      "learning_rate": 9e-06,
      "loss": 0.0,
      "step": 820
    },
    {
      "epoch": 0.821,
      "grad_norm": 0.004721283912658691,
      "learning_rate": 8.95e-06,
      "loss": 0.0001,
      "step": 821
    },
    {
      "epoch": 0.822,
      "grad_norm": 0.006774468347430229,
      "learning_rate": 8.9e-06,
      "loss": 0.0001,
      "step": 822
    },
    {
      "epoch": 0.823,
      "grad_norm": 0.010567480698227882,
      "learning_rate": 8.85e-06,
      "loss": 0.0002,
      "step": 823
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.007510405499488115,
      "learning_rate": 8.8e-06,
      "loss": 0.0001,
      "step": 824
    },
    {
      "epoch": 0.825,
      "grad_norm": 0.1421796828508377,
      "learning_rate": 8.75e-06,
      "loss": 0.0021,
      "step": 825
    },
    {
      "epoch": 0.826,
      "grad_norm": 0.012408284470438957,
      "learning_rate": 8.7e-06,
      "loss": 0.0002,
      "step": 826
    },
    {
      "epoch": 0.827,
      "grad_norm": 0.05570778623223305,
      "learning_rate": 8.65e-06,
      "loss": 0.0012,
      "step": 827
    },
    {
      "epoch": 0.828,
      "grad_norm": 0.0009438227280043066,
      "learning_rate": 8.599999999999999e-06,
      "loss": 0.0,
      "step": 828
    },
    {
      "epoch": 0.829,
      "grad_norm": 0.05840048938989639,
      "learning_rate": 8.550000000000001e-06,
      "loss": 0.0009,
      "step": 829
    },
    {
      "epoch": 0.83,
      "grad_norm": 0.105937659740448,
      "learning_rate": 8.500000000000002e-06,
      "loss": 0.0011,
      "step": 830
    },
    {
      "epoch": 0.831,
      "grad_norm": 0.2693043053150177,
      "learning_rate": 8.45e-06,
      "loss": 0.0034,
      "step": 831
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.008281553164124489,
      "learning_rate": 8.400000000000001e-06,
      "loss": 0.0001,
      "step": 832
    },
    {
      "epoch": 0.833,
      "grad_norm": 0.07757768034934998,
      "learning_rate": 8.350000000000001e-06,
      "loss": 0.0007,
      "step": 833
    },
    {
      "epoch": 0.834,
      "grad_norm": 0.10953428596258163,
      "learning_rate": 8.3e-06,
      "loss": 0.0013,
      "step": 834
    },
    {
      "epoch": 0.835,
      "grad_norm": 0.02460276335477829,
      "learning_rate": 8.25e-06,
      "loss": 0.0004,
      "step": 835
    },
    {
      "epoch": 0.836,
      "grad_norm": 0.07766994833946228,
      "learning_rate": 8.200000000000001e-06,
      "loss": 0.0008,
      "step": 836
    },
    {
      "epoch": 0.837,
      "grad_norm": 0.005793013609945774,
      "learning_rate": 8.15e-06,
      "loss": 0.0001,
      "step": 837
    },
    {
      "epoch": 0.838,
      "grad_norm": 0.16790157556533813,
      "learning_rate": 8.1e-06,
      "loss": 0.0032,
      "step": 838
    },
    {
      "epoch": 0.839,
      "grad_norm": 0.08561140298843384,
      "learning_rate": 8.050000000000001e-06,
      "loss": 0.001,
      "step": 839
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.0561407245695591,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.0007,
      "step": 840
    },
    {
      "epoch": 0.841,
      "grad_norm": 0.17313501238822937,
      "learning_rate": 7.95e-06,
      "loss": 0.0016,
      "step": 841
    },
    {
      "epoch": 0.842,
      "grad_norm": 0.019029252231121063,
      "learning_rate": 7.9e-06,
      "loss": 0.0003,
      "step": 842
    },
    {
      "epoch": 0.843,
      "grad_norm": 0.01868242770433426,
      "learning_rate": 7.850000000000001e-06,
      "loss": 0.0003,
      "step": 843
    },
    {
      "epoch": 0.844,
      "grad_norm": 0.001238398370333016,
      "learning_rate": 7.8e-06,
      "loss": 0.0,
      "step": 844
    },
    {
      "epoch": 0.845,
      "grad_norm": 0.06923119723796844,
      "learning_rate": 7.75e-06,
      "loss": 0.0014,
      "step": 845
    },
    {
      "epoch": 0.846,
      "grad_norm": 0.10754024982452393,
      "learning_rate": 7.7e-06,
      "loss": 0.0019,
      "step": 846
    },
    {
      "epoch": 0.847,
      "grad_norm": 0.2513214945793152,
      "learning_rate": 7.65e-06,
      "loss": 0.0029,
      "step": 847
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.006894360296428204,
      "learning_rate": 7.6e-06,
      "loss": 0.0001,
      "step": 848
    },
    {
      "epoch": 0.849,
      "grad_norm": 0.029691271483898163,
      "learning_rate": 7.55e-06,
      "loss": 0.0005,
      "step": 849
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.08819324523210526,
      "learning_rate": 7.5e-06,
      "loss": 0.0012,
      "step": 850
    },
    {
      "epoch": 0.851,
      "grad_norm": 0.03075750730931759,
      "learning_rate": 7.45e-06,
      "loss": 0.0006,
      "step": 851
    },
    {
      "epoch": 0.852,
      "grad_norm": 0.40457817912101746,
      "learning_rate": 7.4e-06,
      "loss": 0.0028,
      "step": 852
    },
    {
      "epoch": 0.853,
      "grad_norm": 0.05670296773314476,
      "learning_rate": 7.35e-06,
      "loss": 0.0005,
      "step": 853
    },
    {
      "epoch": 0.854,
      "grad_norm": 2.4165585041046143,
      "learning_rate": 7.2999999999999996e-06,
      "loss": 0.0074,
      "step": 854
    },
    {
      "epoch": 0.855,
      "grad_norm": 0.002818981185555458,
      "learning_rate": 7.25e-06,
      "loss": 0.0,
      "step": 855
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.017425406724214554,
      "learning_rate": 7.2e-06,
      "loss": 0.0002,
      "step": 856
    },
    {
      "epoch": 0.857,
      "grad_norm": 0.2060115784406662,
      "learning_rate": 7.15e-06,
      "loss": 0.0016,
      "step": 857
    },
    {
      "epoch": 0.858,
      "grad_norm": 0.10807269811630249,
      "learning_rate": 7.1e-06,
      "loss": 0.0013,
      "step": 858
    },
    {
      "epoch": 0.859,
      "grad_norm": 0.003838786855340004,
      "learning_rate": 7.049999999999999e-06,
      "loss": 0.0001,
      "step": 859
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.016265545040369034,
      "learning_rate": 7.000000000000001e-06,
      "loss": 0.0002,
      "step": 860
    },
    {
      "epoch": 0.861,
      "grad_norm": 0.013487058691680431,
      "learning_rate": 6.950000000000001e-06,
      "loss": 0.0002,
      "step": 861
    },
    {
      "epoch": 0.862,
      "grad_norm": 0.004689692985266447,
      "learning_rate": 6.900000000000001e-06,
      "loss": 0.0001,
      "step": 862
    },
    {
      "epoch": 0.863,
      "grad_norm": 0.37790998816490173,
      "learning_rate": 6.8500000000000005e-06,
      "loss": 0.0043,
      "step": 863
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.028052588924765587,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.0003,
      "step": 864
    },
    {
      "epoch": 0.865,
      "grad_norm": 0.042529843747615814,
      "learning_rate": 6.750000000000001e-06,
      "loss": 0.0009,
      "step": 865
    },
    {
      "epoch": 0.866,
      "grad_norm": 0.009817078709602356,
      "learning_rate": 6.700000000000001e-06,
      "loss": 0.0002,
      "step": 866
    },
    {
      "epoch": 0.867,
      "grad_norm": 0.019980359822511673,
      "learning_rate": 6.650000000000001e-06,
      "loss": 0.0003,
      "step": 867
    },
    {
      "epoch": 0.868,
      "grad_norm": 0.05533142760396004,
      "learning_rate": 6.6e-06,
      "loss": 0.0011,
      "step": 868
    },
    {
      "epoch": 0.869,
      "grad_norm": 0.05113554745912552,
      "learning_rate": 6.550000000000001e-06,
      "loss": 0.0005,
      "step": 869
    },
    {
      "epoch": 0.87,
      "grad_norm": 0.007367847487330437,
      "learning_rate": 6.5000000000000004e-06,
      "loss": 0.0002,
      "step": 870
    },
    {
      "epoch": 0.871,
      "grad_norm": 0.031112579628825188,
      "learning_rate": 6.45e-06,
      "loss": 0.0007,
      "step": 871
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.01508933212608099,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 0.0002,
      "step": 872
    },
    {
      "epoch": 0.873,
      "grad_norm": 0.1844322383403778,
      "learning_rate": 6.35e-06,
      "loss": 0.0018,
      "step": 873
    },
    {
      "epoch": 0.874,
      "grad_norm": 0.0031709657050669193,
      "learning_rate": 6.300000000000001e-06,
      "loss": 0.0001,
      "step": 874
    },
    {
      "epoch": 0.875,
      "grad_norm": 0.012771112844347954,
      "learning_rate": 6.25e-06,
      "loss": 0.0003,
      "step": 875
    },
    {
      "epoch": 0.876,
      "grad_norm": 13.040180206298828,
      "learning_rate": 6.2e-06,
      "loss": 0.2725,
      "step": 876
    },
    {
      "epoch": 0.877,
      "grad_norm": 0.006801959127187729,
      "learning_rate": 6.15e-06,
      "loss": 0.0001,
      "step": 877
    },
    {
      "epoch": 0.878,
      "grad_norm": 0.008281567133963108,
      "learning_rate": 6.1e-06,
      "loss": 0.0001,
      "step": 878
    },
    {
      "epoch": 0.879,
      "grad_norm": 0.020666763186454773,
      "learning_rate": 6.0500000000000005e-06,
      "loss": 0.0003,
      "step": 879
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.00732905138283968,
      "learning_rate": 6e-06,
      "loss": 0.0001,
      "step": 880
    },
    {
      "epoch": 0.881,
      "grad_norm": 0.0037032293621450663,
      "learning_rate": 5.95e-06,
      "loss": 0.0001,
      "step": 881
    },
    {
      "epoch": 0.882,
      "grad_norm": 0.014990140683948994,
      "learning_rate": 5.9e-06,
      "loss": 0.0001,
      "step": 882
    },
    {
      "epoch": 0.883,
      "grad_norm": 0.01509105321019888,
      "learning_rate": 5.850000000000001e-06,
      "loss": 0.0001,
      "step": 883
    },
    {
      "epoch": 0.884,
      "grad_norm": 0.054147351533174515,
      "learning_rate": 5.8e-06,
      "loss": 0.0006,
      "step": 884
    },
    {
      "epoch": 0.885,
      "grad_norm": 0.006229726132005453,
      "learning_rate": 5.750000000000001e-06,
      "loss": 0.0001,
      "step": 885
    },
    {
      "epoch": 0.886,
      "grad_norm": 0.03419101983308792,
      "learning_rate": 5.7000000000000005e-06,
      "loss": 0.0005,
      "step": 886
    },
    {
      "epoch": 0.887,
      "grad_norm": 0.009967495687305927,
      "learning_rate": 5.65e-06,
      "loss": 0.0001,
      "step": 887
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.2524789273738861,
      "learning_rate": 5.600000000000001e-06,
      "loss": 0.0036,
      "step": 888
    },
    {
      "epoch": 0.889,
      "grad_norm": 0.05379467457532883,
      "learning_rate": 5.55e-06,
      "loss": 0.0005,
      "step": 889
    },
    {
      "epoch": 0.89,
      "grad_norm": 0.01566440612077713,
      "learning_rate": 5.500000000000001e-06,
      "loss": 0.0004,
      "step": 890
    },
    {
      "epoch": 0.891,
      "grad_norm": 0.026817936450242996,
      "learning_rate": 5.45e-06,
      "loss": 0.0007,
      "step": 891
    },
    {
      "epoch": 0.892,
      "grad_norm": 0.004558937158435583,
      "learning_rate": 5.4e-06,
      "loss": 0.0001,
      "step": 892
    },
    {
      "epoch": 0.893,
      "grad_norm": 0.031507935374975204,
      "learning_rate": 5.3500000000000004e-06,
      "loss": 0.0004,
      "step": 893
    },
    {
      "epoch": 0.894,
      "grad_norm": 0.015256626531481743,
      "learning_rate": 5.3e-06,
      "loss": 0.0002,
      "step": 894
    },
    {
      "epoch": 0.895,
      "grad_norm": 0.020694386214017868,
      "learning_rate": 5.25e-06,
      "loss": 0.0003,
      "step": 895
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.07502181828022003,
      "learning_rate": 5.2e-06,
      "loss": 0.0007,
      "step": 896
    },
    {
      "epoch": 0.897,
      "grad_norm": 6.696418762207031,
      "learning_rate": 5.15e-06,
      "loss": 0.0199,
      "step": 897
    },
    {
      "epoch": 0.898,
      "grad_norm": 0.006583874113857746,
      "learning_rate": 5.1e-06,
      "loss": 0.0002,
      "step": 898
    },
    {
      "epoch": 0.899,
      "grad_norm": 0.17059248685836792,
      "learning_rate": 5.050000000000001e-06,
      "loss": 0.0027,
      "step": 899
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.013321705162525177,
      "learning_rate": 5e-06,
      "loss": 0.0001,
      "step": 900
    },
    {
      "epoch": 0.901,
      "grad_norm": 0.05181853473186493,
      "learning_rate": 4.950000000000001e-06,
      "loss": 0.0008,
      "step": 901
    },
    {
      "epoch": 0.902,
      "grad_norm": 0.004688975401222706,
      "learning_rate": 4.9000000000000005e-06,
      "loss": 0.0,
      "step": 902
    },
    {
      "epoch": 0.903,
      "grad_norm": 0.06697254627943039,
      "learning_rate": 4.85e-06,
      "loss": 0.0006,
      "step": 903
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.029589353129267693,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.0006,
      "step": 904
    },
    {
      "epoch": 0.905,
      "grad_norm": 0.02178061567246914,
      "learning_rate": 4.75e-06,
      "loss": 0.0003,
      "step": 905
    },
    {
      "epoch": 0.906,
      "grad_norm": 0.0874088928103447,
      "learning_rate": 4.7e-06,
      "loss": 0.0015,
      "step": 906
    },
    {
      "epoch": 0.907,
      "grad_norm": 0.010206705890595913,
      "learning_rate": 4.65e-06,
      "loss": 0.0001,
      "step": 907
    },
    {
      "epoch": 0.908,
      "grad_norm": 0.04754067212343216,
      "learning_rate": 4.6e-06,
      "loss": 0.0007,
      "step": 908
    },
    {
      "epoch": 0.909,
      "grad_norm": 0.03400815650820732,
      "learning_rate": 4.5500000000000005e-06,
      "loss": 0.0002,
      "step": 909
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.003087169723585248,
      "learning_rate": 4.5e-06,
      "loss": 0.0001,
      "step": 910
    },
    {
      "epoch": 0.911,
      "grad_norm": 0.007835844531655312,
      "learning_rate": 4.45e-06,
      "loss": 0.0001,
      "step": 911
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.005073491483926773,
      "learning_rate": 4.4e-06,
      "loss": 0.0001,
      "step": 912
    },
    {
      "epoch": 0.913,
      "grad_norm": 0.023551875725388527,
      "learning_rate": 4.35e-06,
      "loss": 0.0003,
      "step": 913
    },
    {
      "epoch": 0.914,
      "grad_norm": 0.09030120819807053,
      "learning_rate": 4.2999999999999995e-06,
      "loss": 0.0011,
      "step": 914
    },
    {
      "epoch": 0.915,
      "grad_norm": 1.8123674392700195,
      "learning_rate": 4.250000000000001e-06,
      "loss": 0.0211,
      "step": 915
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.10756192356348038,
      "learning_rate": 4.2000000000000004e-06,
      "loss": 0.0016,
      "step": 916
    },
    {
      "epoch": 0.917,
      "grad_norm": 0.039519257843494415,
      "learning_rate": 4.15e-06,
      "loss": 0.0004,
      "step": 917
    },
    {
      "epoch": 0.918,
      "grad_norm": 0.0022887566592544317,
      "learning_rate": 4.1000000000000006e-06,
      "loss": 0.0,
      "step": 918
    },
    {
      "epoch": 0.919,
      "grad_norm": 0.0019654659554362297,
      "learning_rate": 4.05e-06,
      "loss": 0.0,
      "step": 919
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.1598508507013321,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.0018,
      "step": 920
    },
    {
      "epoch": 0.921,
      "grad_norm": 0.0015162474010139704,
      "learning_rate": 3.95e-06,
      "loss": 0.0,
      "step": 921
    },
    {
      "epoch": 0.922,
      "grad_norm": 0.5247700214385986,
      "learning_rate": 3.9e-06,
      "loss": 0.0082,
      "step": 922
    },
    {
      "epoch": 0.923,
      "grad_norm": 0.009020552039146423,
      "learning_rate": 3.85e-06,
      "loss": 0.0002,
      "step": 923
    },
    {
      "epoch": 0.924,
      "grad_norm": 0.008891944773495197,
      "learning_rate": 3.8e-06,
      "loss": 0.0001,
      "step": 924
    },
    {
      "epoch": 0.925,
      "grad_norm": 0.028363315388560295,
      "learning_rate": 3.75e-06,
      "loss": 0.0004,
      "step": 925
    },
    {
      "epoch": 0.926,
      "grad_norm": 0.008043943904340267,
      "learning_rate": 3.7e-06,
      "loss": 0.0002,
      "step": 926
    },
    {
      "epoch": 0.927,
      "grad_norm": 0.02118668332695961,
      "learning_rate": 3.6499999999999998e-06,
      "loss": 0.0003,
      "step": 927
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.00531882094219327,
      "learning_rate": 3.6e-06,
      "loss": 0.0001,
      "step": 928
    },
    {
      "epoch": 0.929,
      "grad_norm": 0.006980022881180048,
      "learning_rate": 3.55e-06,
      "loss": 0.0001,
      "step": 929
    },
    {
      "epoch": 0.93,
      "grad_norm": 0.05191554129123688,
      "learning_rate": 3.5000000000000004e-06,
      "loss": 0.0002,
      "step": 930
    },
    {
      "epoch": 0.931,
      "grad_norm": 0.017428850755095482,
      "learning_rate": 3.4500000000000004e-06,
      "loss": 0.0003,
      "step": 931
    },
    {
      "epoch": 0.932,
      "grad_norm": 0.0012274276232346892,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 0.0,
      "step": 932
    },
    {
      "epoch": 0.933,
      "grad_norm": 0.01708652824163437,
      "learning_rate": 3.3500000000000005e-06,
      "loss": 0.0003,
      "step": 933
    },
    {
      "epoch": 0.934,
      "grad_norm": 0.014842892065644264,
      "learning_rate": 3.3e-06,
      "loss": 0.0001,
      "step": 934
    },
    {
      "epoch": 0.935,
      "grad_norm": 0.06723346561193466,
      "learning_rate": 3.2500000000000002e-06,
      "loss": 0.0007,
      "step": 935
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.08937481045722961,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 0.0013,
      "step": 936
    },
    {
      "epoch": 0.937,
      "grad_norm": 0.02839607372879982,
      "learning_rate": 3.1500000000000003e-06,
      "loss": 0.0006,
      "step": 937
    },
    {
      "epoch": 0.938,
      "grad_norm": 0.05863100290298462,
      "learning_rate": 3.1e-06,
      "loss": 0.0006,
      "step": 938
    },
    {
      "epoch": 0.939,
      "grad_norm": 0.008078431710600853,
      "learning_rate": 3.05e-06,
      "loss": 0.0001,
      "step": 939
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.130524143576622,
      "learning_rate": 3e-06,
      "loss": 0.0016,
      "step": 940
    },
    {
      "epoch": 0.941,
      "grad_norm": 0.011718690395355225,
      "learning_rate": 2.95e-06,
      "loss": 0.0002,
      "step": 941
    },
    {
      "epoch": 0.942,
      "grad_norm": 0.06717803329229355,
      "learning_rate": 2.9e-06,
      "loss": 0.0015,
      "step": 942
    },
    {
      "epoch": 0.943,
      "grad_norm": 0.028796818107366562,
      "learning_rate": 2.8500000000000002e-06,
      "loss": 0.0006,
      "step": 943
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.1707005500793457,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 0.0002,
      "step": 944
    },
    {
      "epoch": 0.945,
      "grad_norm": 0.015154985710978508,
      "learning_rate": 2.7500000000000004e-06,
      "loss": 0.0002,
      "step": 945
    },
    {
      "epoch": 0.946,
      "grad_norm": 0.01355371531099081,
      "learning_rate": 2.7e-06,
      "loss": 0.0002,
      "step": 946
    },
    {
      "epoch": 0.947,
      "grad_norm": 0.05925295129418373,
      "learning_rate": 2.65e-06,
      "loss": 0.0011,
      "step": 947
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.045025650411844254,
      "learning_rate": 2.6e-06,
      "loss": 0.0005,
      "step": 948
    },
    {
      "epoch": 0.949,
      "grad_norm": 0.12822876870632172,
      "learning_rate": 2.55e-06,
      "loss": 0.003,
      "step": 949
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.005811264738440514,
      "learning_rate": 2.5e-06,
      "loss": 0.0001,
      "step": 950
    },
    {
      "epoch": 0.951,
      "grad_norm": 0.020151406526565552,
      "learning_rate": 2.4500000000000003e-06,
      "loss": 0.0003,
      "step": 951
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.055570218712091446,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 0.0009,
      "step": 952
    },
    {
      "epoch": 0.953,
      "grad_norm": 0.01940046437084675,
      "learning_rate": 2.35e-06,
      "loss": 0.0005,
      "step": 953
    },
    {
      "epoch": 0.954,
      "grad_norm": 0.028470562770962715,
      "learning_rate": 2.3e-06,
      "loss": 0.0005,
      "step": 954
    },
    {
      "epoch": 0.955,
      "grad_norm": 0.010061070322990417,
      "learning_rate": 2.25e-06,
      "loss": 0.0002,
      "step": 955
    },
    {
      "epoch": 0.956,
      "grad_norm": 0.020602962002158165,
      "learning_rate": 2.2e-06,
      "loss": 0.0003,
      "step": 956
    },
    {
      "epoch": 0.957,
      "grad_norm": 0.055466316640377045,
      "learning_rate": 2.1499999999999997e-06,
      "loss": 0.0008,
      "step": 957
    },
    {
      "epoch": 0.958,
      "grad_norm": 0.0031743429135531187,
      "learning_rate": 2.1000000000000002e-06,
      "loss": 0.0001,
      "step": 958
    },
    {
      "epoch": 0.959,
      "grad_norm": 16.77277374267578,
      "learning_rate": 2.0500000000000003e-06,
      "loss": 0.039,
      "step": 959
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.030761823058128357,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.0003,
      "step": 960
    },
    {
      "epoch": 0.961,
      "grad_norm": 0.0008884996059350669,
      "learning_rate": 1.95e-06,
      "loss": 0.0,
      "step": 961
    },
    {
      "epoch": 0.962,
      "grad_norm": 0.03384031727910042,
      "learning_rate": 1.9e-06,
      "loss": 0.0003,
      "step": 962
    },
    {
      "epoch": 0.963,
      "grad_norm": 0.047300368547439575,
      "learning_rate": 1.85e-06,
      "loss": 0.0007,
      "step": 963
    },
    {
      "epoch": 0.964,
      "grad_norm": 0.020723454654216766,
      "learning_rate": 1.8e-06,
      "loss": 0.0002,
      "step": 964
    },
    {
      "epoch": 0.965,
      "grad_norm": 0.005199544597417116,
      "learning_rate": 1.7500000000000002e-06,
      "loss": 0.0001,
      "step": 965
    },
    {
      "epoch": 0.966,
      "grad_norm": 0.008786236867308617,
      "learning_rate": 1.7000000000000002e-06,
      "loss": 0.0001,
      "step": 966
    },
    {
      "epoch": 0.967,
      "grad_norm": 0.00709920097142458,
      "learning_rate": 1.65e-06,
      "loss": 0.0002,
      "step": 967
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.09142174571752548,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 0.0012,
      "step": 968
    },
    {
      "epoch": 0.969,
      "grad_norm": 0.011856526136398315,
      "learning_rate": 1.55e-06,
      "loss": 0.0002,
      "step": 969
    },
    {
      "epoch": 0.97,
      "grad_norm": 0.05157031863927841,
      "learning_rate": 1.5e-06,
      "loss": 0.0006,
      "step": 970
    },
    {
      "epoch": 0.971,
      "grad_norm": 0.007154545746743679,
      "learning_rate": 1.45e-06,
      "loss": 0.0001,
      "step": 971
    },
    {
      "epoch": 0.972,
      "grad_norm": 0.02933960035443306,
      "learning_rate": 1.4000000000000001e-06,
      "loss": 0.0005,
      "step": 972
    },
    {
      "epoch": 0.973,
      "grad_norm": 0.007603984791785479,
      "learning_rate": 1.35e-06,
      "loss": 0.0001,
      "step": 973
    },
    {
      "epoch": 0.974,
      "grad_norm": 0.01126972958445549,
      "learning_rate": 1.3e-06,
      "loss": 0.0,
      "step": 974
    },
    {
      "epoch": 0.975,
      "grad_norm": 0.001825231360271573,
      "learning_rate": 1.25e-06,
      "loss": 0.0,
      "step": 975
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.01483655534684658,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 0.0002,
      "step": 976
    },
    {
      "epoch": 0.977,
      "grad_norm": 0.05622449144721031,
      "learning_rate": 1.15e-06,
      "loss": 0.0011,
      "step": 977
    },
    {
      "epoch": 0.978,
      "grad_norm": 0.01029587909579277,
      "learning_rate": 1.1e-06,
      "loss": 0.0001,
      "step": 978
    },
    {
      "epoch": 0.979,
      "grad_norm": 0.030571436509490013,
      "learning_rate": 1.0500000000000001e-06,
      "loss": 0.0005,
      "step": 979
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.21169276535511017,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.002,
      "step": 980
    },
    {
      "epoch": 0.981,
      "grad_norm": 0.036632753908634186,
      "learning_rate": 9.5e-07,
      "loss": 0.0004,
      "step": 981
    },
    {
      "epoch": 0.982,
      "grad_norm": 0.0015132982516661286,
      "learning_rate": 9e-07,
      "loss": 0.0,
      "step": 982
    },
    {
      "epoch": 0.983,
      "grad_norm": 0.008487283252179623,
      "learning_rate": 8.500000000000001e-07,
      "loss": 0.0001,
      "step": 983
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.003094910178333521,
      "learning_rate": 8.000000000000001e-07,
      "loss": 0.0,
      "step": 984
    },
    {
      "epoch": 0.985,
      "grad_norm": 0.010551565326750278,
      "learning_rate": 7.5e-07,
      "loss": 0.0002,
      "step": 985
    },
    {
      "epoch": 0.986,
      "grad_norm": 0.005623771343380213,
      "learning_rate": 7.000000000000001e-07,
      "loss": 0.0001,
      "step": 986
    },
    {
      "epoch": 0.987,
      "grad_norm": 0.1391371637582779,
      "learning_rate": 6.5e-07,
      "loss": 0.0016,
      "step": 987
    },
    {
      "epoch": 0.988,
      "grad_norm": 0.030154090374708176,
      "learning_rate": 6.000000000000001e-07,
      "loss": 0.0004,
      "step": 988
    },
    {
      "epoch": 0.989,
      "grad_norm": 0.0018071618396788836,
      "learning_rate": 5.5e-07,
      "loss": 0.0,
      "step": 989
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.00653226999565959,
      "learning_rate": 5.000000000000001e-07,
      "loss": 0.0001,
      "step": 990
    },
    {
      "epoch": 0.991,
      "grad_norm": 0.21522346138954163,
      "learning_rate": 4.5e-07,
      "loss": 0.003,
      "step": 991
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.017806852236390114,
      "learning_rate": 4.0000000000000003e-07,
      "loss": 0.0002,
      "step": 992
    },
    {
      "epoch": 0.993,
      "grad_norm": 0.021090932190418243,
      "learning_rate": 3.5000000000000004e-07,
      "loss": 0.0003,
      "step": 993
    },
    {
      "epoch": 0.994,
      "grad_norm": 0.008658167906105518,
      "learning_rate": 3.0000000000000004e-07,
      "loss": 0.0001,
      "step": 994
    },
    {
      "epoch": 0.995,
      "grad_norm": 0.0003981606860179454,
      "learning_rate": 2.5000000000000004e-07,
      "loss": 0.0,
      "step": 995
    },
    {
      "epoch": 0.996,
      "grad_norm": 0.0017501026159152389,
      "learning_rate": 2.0000000000000002e-07,
      "loss": 0.0,
      "step": 996
    },
    {
      "epoch": 0.997,
      "grad_norm": 0.05981609225273132,
      "learning_rate": 1.5000000000000002e-07,
      "loss": 0.0004,
      "step": 997
    },
    {
      "epoch": 0.998,
      "grad_norm": 0.1179165467619896,
      "learning_rate": 1.0000000000000001e-07,
      "loss": 0.0019,
      "step": 998
    },
    {
      "epoch": 0.999,
      "grad_norm": 0.002581218024715781,
      "learning_rate": 5.0000000000000004e-08,
      "loss": 0.0,
      "step": 999
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.055019427090883255,
      "learning_rate": 0.0,
      "loss": 0.0006,
      "step": 1000
    }
  ],
  "logging_steps": 1,
  "max_steps": 1000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 23236313088000.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
